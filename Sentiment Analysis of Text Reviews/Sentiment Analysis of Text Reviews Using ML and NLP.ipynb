{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Restaurant Reviews Through Machine Learning and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement**\n",
    "\n",
    "There are a total of 3,000 restaurant reviews that have been classified as either positive reviews or negative reviews; 2,400 of these reviews form the training dataset and the remaining 600 reviews form the test dataset.\n",
    "\n",
    "Based on the data provided, a model is built that can classify these reviews as positive or negative (0 or 1) using NLP and ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\Hassan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  600 non-null    object\n",
      " 1   Polarity  600 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0  A good commentary of today's love and undoubte...         1\n",
      "1  For people who are first timers in film making...         1\n",
      "2  It was very popular when I was in the cinema, ...         1\n",
      "3  It's a feel-good film and that's how I felt wh...         1\n",
      "4  It has northern humour and positive about the ...         1\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_test.info())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence    0\n",
       "Polarity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Sentence    0\n",
       "Polarity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if there's any missing values as blanks or nulls\n",
    "\n",
    "df_train = df_train.replace(' ', np.nan)\n",
    "df_train.isnull().sum()\n",
    "\n",
    "df_test = df_test.replace(' ', np.nan)\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.505417\n",
       "1    0.494583\n",
       "Name: Polarity, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking data balance -> data is balanced\n",
    "\n",
    "df_train['Polarity'].value_counts(normalize = True)\n",
    "df_train['Polarity'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if length of sentences contribute to polarity score - adding length feature\n",
    "\n",
    "df_train['length']= df_train.Sentence.str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity  length\n",
       "0                           Wow... Loved this place.         1       4\n",
       "1                                 Crust is not good.         0       4\n",
       "2          Not tasty and the texture was just nasty.         0       8\n",
       "3  Stopped by during the late May bank holiday of...         1      15\n",
       "4  The selection on the menu was great and so wer...         1      12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting histogram of sentences against length -> significant overlap of histograms \n",
    "#suggest there is no relation between length and polarity score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df_train[df_train['Polarity']==0]['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df_train[df_train['Polarity']==1]['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('0','1'))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(df_train['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    r = re.sub('[^a-zA-Z]', ' ', text[i])\n",
    "    r = r.lower()\n",
    "    r = r.split()\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "    r = [lemmatizer.lemmatize(word) for word in r]\n",
    "    r = ' '.join(r)\n",
    "    corpus.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow loved place'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split (followed by Vectorization Fit on Training Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split (66% train - 33% test)\n",
    "X = np.array(corpus)\n",
    "y = df_train['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : (1608,)\n",
      "Testing Data :  (792,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, \n",
    "                                                    random_state=123)\n",
    "\n",
    "print('Training Data :', X_train.shape)\n",
    "print('Testing Data : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1608, 2789)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit transform the TfidfVectorizer\n",
    "X_train_vector= tfidf.fit_transform(X_train)\n",
    "X_train_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Different ML Algorithms (LR, NB, SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vector, y_train)\n",
    "\n",
    "X_test_vector = tfidf.transform(X_test)\n",
    "lr_predictions = lr.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  321   67\n",
       "1  105  299"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       388\n",
      "           1       0.82      0.74      0.78       404\n",
      "\n",
      "    accuracy                           0.78       792\n",
      "   macro avg       0.79      0.78      0.78       792\n",
      "weighted avg       0.79      0.78      0.78       792\n",
      "\n",
      "0.8737655659895887\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test,lr_predictions), \n",
    "             index=['0','1'], columns=['0','1'])\n",
    "\n",
    "print(metrics.classification_report(y_test,lr_predictions))\n",
    "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test_vector)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(X_train_vector.toarray(), y_train)\n",
    "\n",
    "gnb_predictions = gnb.predict(X_test_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  220  168\n",
       "1   92  312"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       388\n",
      "           1       0.65      0.77      0.71       404\n",
      "\n",
      "    accuracy                           0.67       792\n",
      "   macro avg       0.68      0.67      0.67       792\n",
      "weighted avg       0.68      0.67      0.67       792\n",
      "\n",
      "0.6701796468306624\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_test,gnb_predictions), \n",
    "             index=['0','1'], columns=['0','1'])\n",
    "\n",
    "print(metrics.classification_report(y_test,gnb_predictions))\n",
    "print(metrics.roc_auc_score(y_test,gnb.predict_proba(X_test_vector.toarray())[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.025, kernel='linear')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"linear\", C=0.025)\n",
    "svm.fit(X_train_vector, y_train)\n",
    "\n",
    "svm_predictions = svm.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0  388  0\n",
       "1  403  1"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       388\n",
      "           1       1.00      0.00      0.00       404\n",
      "\n",
      "    accuracy                           0.49       792\n",
      "   macro avg       0.75      0.50      0.33       792\n",
      "weighted avg       0.75      0.49      0.32       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_test,svm_predictions), \n",
    "             index=['0','1'], columns=['0','1'])\n",
    "\n",
    "print(metrics.classification_report(y_test,svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression yielded the best score amongst LR, Naive Bayes and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limited Text Preprocessing (removing stopword remover and Lemmatizer) + Using Vectorizer with n-gram range + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    r = re.sub('[^a-zA-Z]', ' ', text[i])\n",
    "    r = r.lower()\n",
    "    r = r.split()\n",
    "    r = ' '.join(r)\n",
    "    corpus2.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow loved this place'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : (1608,)\n",
      "Testing Data :  (792,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1608, 13876)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  327   61\n",
       "1   86  318"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       388\n",
      "           1       0.84      0.79      0.81       404\n",
      "\n",
      "    accuracy                           0.81       792\n",
      "   macro avg       0.82      0.81      0.81       792\n",
      "weighted avg       0.82      0.81      0.81       792\n",
      "\n",
      "0.9062946565275083\n"
     ]
    }
   ],
   "source": [
    "# train test split (66% train - 33% test)\n",
    "X = np.array(corpus2)\n",
    "y = df_train['Polarity']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, \n",
    "                                                    random_state=123)\n",
    "\n",
    "print('Training Data :', X_train.shape)\n",
    "print('Testing Data : ', X_test.shape)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# fit transform the TfidfVectorizer\n",
    "X_train_vector= tfidf.fit_transform(X_train)\n",
    "X_train_vector.shape\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vector, y_train)\n",
    "\n",
    "X_test_vector = tfidf.transform(X_test)\n",
    "lr_predictions = lr.predict(X_test_vector)\n",
    "\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test,lr_predictions), \n",
    "             index=['0','1'], columns=['0','1'])\n",
    "\n",
    "print(metrics.classification_report(y_test,lr_predictions))\n",
    "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test_vector)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC has improved from 0.8737 to 0.9063 with these steps while accuracy/F1 scores have increased from 0.78 to 0.81\n",
    "### This suggests that removing stopwords or lemmatizing words lowered the ability of the algorithm to differentiate between positive and negative sentences as some negative words such as 'not', 'dont', 'no' are considered as stopwords by NLTK. Another observation is that using n-gram range (1,2) helps the algorithm as there are some bigrams in the sentences as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial,X_train_vector,y_train):\n",
    "    \n",
    "    hyper_params_lr = {\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\",[\"balanced\",None]),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\",100,10000,step=10),\n",
    "        \"multi_class\": trial.suggest_categorical(\"multi_class\",\n",
    "                                                 [\"auto\",\"ovr\",\"multinomial\"]),\n",
    "        \"C\": trial.suggest_float(\"C\",0.1,100,step=0.1),    \n",
    "        \"random_state\": 17,\n",
    "}\n",
    "\n",
    "    \n",
    "    \n",
    "    LR = LogisticRegression(**hyper_params_lr)\n",
    "    \n",
    "    cv_scores_lr = cross_val_score(LR,X_train_vector,y_train,cv=2,scoring=\"f1_micro\")\n",
    "    score = np.mean(cv_scores_lr)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:34:15,289]\u001b[0m A new study created in memory with name: no-name-3cf248a1-5c87-4c8a-ad05-80f4fc9e999e\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:34:18,758]\u001b[0m Trial 0 finished with value: 0.7804726368159205 and parameters: {'class_weight': 'balanced', 'max_iter': 590, 'multi_class': 'auto', 'C': 65.89999999999999}. Best is trial 0 with value: 0.7804726368159205.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:19,085]\u001b[0m Trial 1 finished with value: 0.7810945273631842 and parameters: {'class_weight': 'balanced', 'max_iter': 5110, 'multi_class': 'ovr', 'C': 75.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:19,307]\u001b[0m Trial 2 finished with value: 0.7730099502487563 and parameters: {'class_weight': 'balanced', 'max_iter': 370, 'multi_class': 'ovr', 'C': 3.9000000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:19,535]\u001b[0m Trial 3 finished with value: 0.7730099502487562 and parameters: {'class_weight': None, 'max_iter': 8770, 'multi_class': 'auto', 'C': 6.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:19,843]\u001b[0m Trial 4 finished with value: 0.779228855721393 and parameters: {'class_weight': None, 'max_iter': 4400, 'multi_class': 'ovr', 'C': 49.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:20,360]\u001b[0m Trial 5 finished with value: 0.7804726368159205 and parameters: {'class_weight': 'balanced', 'max_iter': 4780, 'multi_class': 'multinomial', 'C': 88.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:20,618]\u001b[0m Trial 6 finished with value: 0.7810945273631842 and parameters: {'class_weight': 'balanced', 'max_iter': 5010, 'multi_class': 'ovr', 'C': 80.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:20,916]\u001b[0m Trial 7 finished with value: 0.779228855721393 and parameters: {'class_weight': None, 'max_iter': 5260, 'multi_class': 'auto', 'C': 49.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:21,283]\u001b[0m Trial 8 finished with value: 0.7804726368159205 and parameters: {'class_weight': 'balanced', 'max_iter': 7540, 'multi_class': 'ovr', 'C': 92.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:21,569]\u001b[0m Trial 9 finished with value: 0.7804726368159205 and parameters: {'class_weight': 'balanced', 'max_iter': 1170, 'multi_class': 'ovr', 'C': 87.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:21,946]\u001b[0m Trial 10 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 3040, 'multi_class': 'multinomial', 'C': 28.400000000000002}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:22,195]\u001b[0m Trial 11 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 6780, 'multi_class': 'ovr', 'C': 71.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:22,468]\u001b[0m Trial 12 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 2710, 'multi_class': 'ovr', 'C': 70.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:22,777]\u001b[0m Trial 13 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 6890, 'multi_class': 'ovr', 'C': 99.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:23,243]\u001b[0m Trial 14 finished with value: 0.7798507462686568 and parameters: {'class_weight': None, 'max_iter': 9900, 'multi_class': 'multinomial', 'C': 61.50000000000001}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:23,526]\u001b[0m Trial 15 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 5660, 'multi_class': 'ovr', 'C': 81.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:23,808]\u001b[0m Trial 16 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 3420, 'multi_class': 'ovr', 'C': 77.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:24,056]\u001b[0m Trial 17 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 5830, 'multi_class': 'ovr', 'C': 55.900000000000006}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:24,340]\u001b[0m Trial 18 finished with value: 0.7761194029850746 and parameters: {'class_weight': None, 'max_iter': 3930, 'multi_class': 'auto', 'C': 19.800000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:24,756]\u001b[0m Trial 19 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 2500, 'multi_class': 'multinomial', 'C': 37.800000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:25,022]\u001b[0m Trial 20 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 7920, 'multi_class': 'ovr', 'C': 79.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:25,293]\u001b[0m Trial 21 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 1900, 'multi_class': 'auto', 'C': 67.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:25,604]\u001b[0m Trial 22 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 320, 'multi_class': 'auto', 'C': 61.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:25,941]\u001b[0m Trial 23 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 6330, 'multi_class': 'auto', 'C': 76.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:26,185]\u001b[0m Trial 24 finished with value: 0.779228855721393 and parameters: {'class_weight': None, 'max_iter': 1530, 'multi_class': 'auto', 'C': 40.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:26,434]\u001b[0m Trial 25 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 3830, 'multi_class': 'auto', 'C': 64.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:26,742]\u001b[0m Trial 26 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 4610, 'multi_class': 'ovr', 'C': 53.800000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:27,148]\u001b[0m Trial 27 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8480, 'multi_class': 'multinomial', 'C': 99.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:27,597]\u001b[0m Trial 28 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8820, 'multi_class': 'multinomial', 'C': 97.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:28,013]\u001b[0m Trial 29 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9600, 'multi_class': 'multinomial', 'C': 89.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:28,495]\u001b[0m Trial 30 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9880, 'multi_class': 'multinomial', 'C': 85.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:28,942]\u001b[0m Trial 31 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9260, 'multi_class': 'multinomial', 'C': 84.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:29,425]\u001b[0m Trial 32 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9530, 'multi_class': 'multinomial', 'C': 93.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:29,884]\u001b[0m Trial 33 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 7490, 'multi_class': 'multinomial', 'C': 75.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:30,374]\u001b[0m Trial 34 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9060, 'multi_class': 'multinomial', 'C': 82.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:34:30,806]\u001b[0m Trial 35 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8350, 'multi_class': 'multinomial', 'C': 93.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:31,237]\u001b[0m Trial 36 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8310, 'multi_class': 'multinomial', 'C': 92.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:31,537]\u001b[0m Trial 37 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 5180, 'multi_class': 'ovr', 'C': 82.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:31,819]\u001b[0m Trial 38 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 7070, 'multi_class': 'ovr', 'C': 91.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:32,334]\u001b[0m Trial 39 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8450, 'multi_class': 'multinomial', 'C': 93.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:32,534]\u001b[0m Trial 40 finished with value: 0.7512437810945273 and parameters: {'class_weight': None, 'max_iter': 6230, 'multi_class': 'ovr', 'C': 0.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:32,991]\u001b[0m Trial 41 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9500, 'multi_class': 'multinomial', 'C': 100.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:33,415]\u001b[0m Trial 42 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7980, 'multi_class': 'multinomial', 'C': 95.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:33,855]\u001b[0m Trial 43 finished with value: 0.7798507462686568 and parameters: {'class_weight': None, 'max_iter': 7850, 'multi_class': 'multinomial', 'C': 72.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:34,303]\u001b[0m Trial 44 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4310, 'multi_class': 'multinomial', 'C': 96.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:34,745]\u001b[0m Trial 45 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4310, 'multi_class': 'multinomial', 'C': 97.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:35,060]\u001b[0m Trial 46 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 4950, 'multi_class': 'ovr', 'C': 87.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:35,366]\u001b[0m Trial 47 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8770, 'multi_class': 'ovr', 'C': 89.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:35,949]\u001b[0m Trial 48 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9590, 'multi_class': 'multinomial', 'C': 99.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:36,312]\u001b[0m Trial 49 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 9790, 'multi_class': 'ovr', 'C': 86.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:36,823]\u001b[0m Trial 50 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5590, 'multi_class': 'multinomial', 'C': 78.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:37,254]\u001b[0m Trial 51 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5540, 'multi_class': 'multinomial', 'C': 85.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:37,795]\u001b[0m Trial 52 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 10000, 'multi_class': 'multinomial', 'C': 84.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:38,239]\u001b[0m Trial 53 finished with value: 0.7798507462686568 and parameters: {'class_weight': None, 'max_iter': 9880, 'multi_class': 'multinomial', 'C': 69.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:38,700]\u001b[0m Trial 54 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 9000, 'multi_class': 'multinomial', 'C': 73.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:39,026]\u001b[0m Trial 55 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 9230, 'multi_class': 'ovr', 'C': 80.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:39,516]\u001b[0m Trial 56 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 800, 'multi_class': 'multinomial', 'C': 89.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:39,788]\u001b[0m Trial 57 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8730, 'multi_class': 'ovr', 'C': 84.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:40,181]\u001b[0m Trial 58 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 9200, 'multi_class': 'multinomial', 'C': 44.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:40,429]\u001b[0m Trial 59 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 9390, 'multi_class': 'ovr', 'C': 62.400000000000006}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:40,895]\u001b[0m Trial 60 finished with value: 0.7798507462686568 and parameters: {'class_weight': None, 'max_iter': 3310, 'multi_class': 'multinomial', 'C': 66.39999999999999}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:41,347]\u001b[0m Trial 61 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9100, 'multi_class': 'multinomial', 'C': 82.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:41,734]\u001b[0m Trial 62 finished with value: 0.775497512437811 and parameters: {'class_weight': None, 'max_iter': 9520, 'multi_class': 'multinomial', 'C': 14.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:42,150]\u001b[0m Trial 63 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9680, 'multi_class': 'multinomial', 'C': 79.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:42,590]\u001b[0m Trial 64 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7400, 'multi_class': 'multinomial', 'C': 88.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:42,950]\u001b[0m Trial 65 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 10000, 'multi_class': 'auto', 'C': 78.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:43,420]\u001b[0m Trial 66 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6060, 'multi_class': 'multinomial', 'C': 88.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:43,870]\u001b[0m Trial 67 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 6570, 'multi_class': 'multinomial', 'C': 57.800000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:44,190]\u001b[0m Trial 68 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 4010, 'multi_class': 'ovr', 'C': 94.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:44,707]\u001b[0m Trial 69 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2340, 'multi_class': 'multinomial', 'C': 82.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:34:45,056]\u001b[0m Trial 70 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 8890, 'multi_class': 'auto', 'C': 75.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:45,590]\u001b[0m Trial 71 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8480, 'multi_class': 'multinomial', 'C': 91.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:46,138]\u001b[0m Trial 72 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9320, 'multi_class': 'multinomial', 'C': 92.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:46,585]\u001b[0m Trial 73 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8540, 'multi_class': 'multinomial', 'C': 81.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:47,101]\u001b[0m Trial 74 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8010, 'multi_class': 'multinomial', 'C': 94.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:47,561]\u001b[0m Trial 75 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8080, 'multi_class': 'multinomial', 'C': 97.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:47,927]\u001b[0m Trial 76 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 8060, 'multi_class': 'ovr', 'C': 97.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:48,375]\u001b[0m Trial 77 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4360, 'multi_class': 'multinomial', 'C': 100.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:48,847]\u001b[0m Trial 78 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4330, 'multi_class': 'multinomial', 'C': 96.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:49,147]\u001b[0m Trial 79 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8320, 'multi_class': 'ovr', 'C': 94.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:49,588]\u001b[0m Trial 80 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4780, 'multi_class': 'multinomial', 'C': 96.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:50,020]\u001b[0m Trial 81 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4800, 'multi_class': 'multinomial', 'C': 99.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:50,451]\u001b[0m Trial 82 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4850, 'multi_class': 'multinomial', 'C': 96.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:50,868]\u001b[0m Trial 83 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7680, 'multi_class': 'multinomial', 'C': 91.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:51,336]\u001b[0m Trial 84 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5260, 'multi_class': 'multinomial', 'C': 94.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:51,815]\u001b[0m Trial 85 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7250, 'multi_class': 'multinomial', 'C': 91.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:52,267]\u001b[0m Trial 86 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5340, 'multi_class': 'multinomial', 'C': 94.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:52,612]\u001b[0m Trial 87 finished with value: 0.7767412935323383 and parameters: {'class_weight': None, 'max_iter': 5590, 'multi_class': 'ovr', 'C': 31.200000000000003}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:52,938]\u001b[0m Trial 88 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8840, 'multi_class': 'auto', 'C': 84.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:53,401]\u001b[0m Trial 89 finished with value: 0.7798507462686568 and parameters: {'class_weight': None, 'max_iter': 5450, 'multi_class': 'multinomial', 'C': 71.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:53,674]\u001b[0m Trial 90 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 3660, 'multi_class': 'ovr', 'C': 84.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:54,174]\u001b[0m Trial 91 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5030, 'multi_class': 'multinomial', 'C': 86.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:54,673]\u001b[0m Trial 92 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 140, 'multi_class': 'multinomial', 'C': 77.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:55,190]\u001b[0m Trial 93 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6020, 'multi_class': 'multinomial', 'C': 81.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:55,671]\u001b[0m Trial 94 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5810, 'multi_class': 'multinomial', 'C': 86.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:56,086]\u001b[0m Trial 95 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 9680, 'multi_class': 'multinomial', 'C': 89.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:56,522]\u001b[0m Trial 96 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 920, 'multi_class': 'multinomial', 'C': 89.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:56,990]\u001b[0m Trial 97 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6660, 'multi_class': 'multinomial', 'C': 78.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:57,450]\u001b[0m Trial 98 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2390, 'multi_class': 'multinomial', 'C': 88.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:57,715]\u001b[0m Trial 99 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 9090, 'multi_class': 'ovr', 'C': 74.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:58,147]\u001b[0m Trial 100 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7730, 'multi_class': 'multinomial', 'C': 92.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:58,596]\u001b[0m Trial 101 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2140, 'multi_class': 'multinomial', 'C': 81.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:59,052]\u001b[0m Trial 102 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6330, 'multi_class': 'multinomial', 'C': 83.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:59,552]\u001b[0m Trial 103 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 690, 'multi_class': 'multinomial', 'C': 80.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:34:59,991]\u001b[0m Trial 104 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8610, 'multi_class': 'multinomial', 'C': 87.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:35:00,441]\u001b[0m Trial 105 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8610, 'multi_class': 'multinomial', 'C': 79.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:00,860]\u001b[0m Trial 106 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7290, 'multi_class': 'multinomial', 'C': 91.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:01,121]\u001b[0m Trial 107 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 9370, 'multi_class': 'ovr', 'C': 69.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:01,406]\u001b[0m Trial 108 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 4490, 'multi_class': 'auto', 'C': 98.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:01,804]\u001b[0m Trial 109 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8170, 'multi_class': 'multinomial', 'C': 93.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:02,245]\u001b[0m Trial 110 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8110, 'multi_class': 'multinomial', 'C': 94.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:02,667]\u001b[0m Trial 111 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8290, 'multi_class': 'multinomial', 'C': 93.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:03,151]\u001b[0m Trial 112 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8250, 'multi_class': 'multinomial', 'C': 98.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:03,580]\u001b[0m Trial 113 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4670, 'multi_class': 'multinomial', 'C': 96.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:04,014]\u001b[0m Trial 114 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3090, 'multi_class': 'multinomial', 'C': 99.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:04,481]\u001b[0m Trial 115 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3200, 'multi_class': 'multinomial', 'C': 99.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:04,746]\u001b[0m Trial 116 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 2840, 'multi_class': 'ovr', 'C': 95.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:05,213]\u001b[0m Trial 117 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5810, 'multi_class': 'multinomial', 'C': 89.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:05,694]\u001b[0m Trial 118 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5060, 'multi_class': 'multinomial', 'C': 90.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:06,159]\u001b[0m Trial 119 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4940, 'multi_class': 'multinomial', 'C': 95.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:06,591]\u001b[0m Trial 120 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4140, 'multi_class': 'multinomial', 'C': 96.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:07,040]\u001b[0m Trial 121 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4120, 'multi_class': 'multinomial', 'C': 96.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:07,505]\u001b[0m Trial 122 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4180, 'multi_class': 'multinomial', 'C': 91.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:07,986]\u001b[0m Trial 123 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5330, 'multi_class': 'multinomial', 'C': 100.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:08,471]\u001b[0m Trial 124 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4790, 'multi_class': 'multinomial', 'C': 95.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:08,901]\u001b[0m Trial 125 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5240, 'multi_class': 'multinomial', 'C': 86.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:09,201]\u001b[0m Trial 126 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 5160, 'multi_class': 'ovr', 'C': 86.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:09,498]\u001b[0m Trial 127 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 9770, 'multi_class': 'auto', 'C': 76.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:09,913]\u001b[0m Trial 128 finished with value: 0.7798507462686568 and parameters: {'class_weight': None, 'max_iter': 6100, 'multi_class': 'multinomial', 'C': 73.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:10,342]\u001b[0m Trial 129 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5610, 'multi_class': 'multinomial', 'C': 84.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:10,863]\u001b[0m Trial 130 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7130, 'multi_class': 'multinomial', 'C': 86.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:11,403]\u001b[0m Trial 131 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 6530, 'multi_class': 'multinomial', 'C': 76.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:11,910]\u001b[0m Trial 132 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5810, 'multi_class': 'multinomial', 'C': 83.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:12,339]\u001b[0m Trial 133 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5440, 'multi_class': 'multinomial', 'C': 89.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:12,791]\u001b[0m Trial 134 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6040, 'multi_class': 'multinomial', 'C': 88.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:13,239]\u001b[0m Trial 135 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5930, 'multi_class': 'multinomial', 'C': 86.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:13,723]\u001b[0m Trial 136 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6820, 'multi_class': 'multinomial', 'C': 78.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:14,050]\u001b[0m Trial 137 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 6710, 'multi_class': 'ovr', 'C': 78.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:14,519]\u001b[0m Trial 138 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6960, 'multi_class': 'multinomial', 'C': 92.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:14,984]\u001b[0m Trial 139 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6480, 'multi_class': 'multinomial', 'C': 82.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:35:15,449]\u001b[0m Trial 140 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1130, 'multi_class': 'multinomial', 'C': 88.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:15,851]\u001b[0m Trial 141 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1580, 'multi_class': 'multinomial', 'C': 89.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:16,331]\u001b[0m Trial 142 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1910, 'multi_class': 'multinomial', 'C': 84.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:16,813]\u001b[0m Trial 143 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6260, 'multi_class': 'multinomial', 'C': 81.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:17,217]\u001b[0m Trial 144 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 7210, 'multi_class': 'multinomial', 'C': 50.900000000000006}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:17,732]\u001b[0m Trial 145 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 770, 'multi_class': 'multinomial', 'C': 80.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:18,192]\u001b[0m Trial 146 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1200, 'multi_class': 'multinomial', 'C': 80.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:18,616]\u001b[0m Trial 147 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 470, 'multi_class': 'multinomial', 'C': 82.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:19,060]\u001b[0m Trial 148 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7660, 'multi_class': 'multinomial', 'C': 86.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:19,358]\u001b[0m Trial 149 finished with value: 0.7779850746268657 and parameters: {'class_weight': None, 'max_iter': 2380, 'multi_class': 'ovr', 'C': 76.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:19,755]\u001b[0m Trial 150 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 7410, 'multi_class': 'multinomial', 'C': 74.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:20,184]\u001b[0m Trial 151 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8630, 'multi_class': 'multinomial', 'C': 83.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:20,611]\u001b[0m Trial 152 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7680, 'multi_class': 'multinomial', 'C': 91.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:20,993]\u001b[0m Trial 153 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7850, 'multi_class': 'multinomial', 'C': 79.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:21,483]\u001b[0m Trial 154 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7850, 'multi_class': 'multinomial', 'C': 80.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:21,893]\u001b[0m Trial 155 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3660, 'multi_class': 'multinomial', 'C': 90.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:22,348]\u001b[0m Trial 156 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1690, 'multi_class': 'multinomial', 'C': 88.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:22,804]\u001b[0m Trial 157 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2020, 'multi_class': 'multinomial', 'C': 93.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:23,370]\u001b[0m Trial 158 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8220, 'multi_class': 'multinomial', 'C': 93.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:23,696]\u001b[0m Trial 159 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8220, 'multi_class': 'auto', 'C': 92.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:23,999]\u001b[0m Trial 160 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 4570, 'multi_class': 'ovr', 'C': 96.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:24,476]\u001b[0m Trial 161 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3440, 'multi_class': 'multinomial', 'C': 98.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:25,013]\u001b[0m Trial 162 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2580, 'multi_class': 'multinomial', 'C': 94.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:25,456]\u001b[0m Trial 163 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8410, 'multi_class': 'multinomial', 'C': 99.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:25,957]\u001b[0m Trial 164 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8120, 'multi_class': 'multinomial', 'C': 97.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:26,354]\u001b[0m Trial 165 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3140, 'multi_class': 'multinomial', 'C': 98.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:26,909]\u001b[0m Trial 166 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2870, 'multi_class': 'multinomial', 'C': 95.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:27,459]\u001b[0m Trial 167 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8530, 'multi_class': 'multinomial', 'C': 91.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:27,989]\u001b[0m Trial 168 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8680, 'multi_class': 'multinomial', 'C': 91.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:28,573]\u001b[0m Trial 169 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4680, 'multi_class': 'multinomial', 'C': 95.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:28,853]\u001b[0m Trial 170 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 4930, 'multi_class': 'ovr', 'C': 95.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:29,316]\u001b[0m Trial 171 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5100, 'multi_class': 'multinomial', 'C': 90.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:29,773]\u001b[0m Trial 172 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4350, 'multi_class': 'multinomial', 'C': 100.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:30,234]\u001b[0m Trial 173 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3900, 'multi_class': 'multinomial', 'C': 95.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:30,675]\u001b[0m Trial 174 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4070, 'multi_class': 'multinomial', 'C': 93.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:35:31,124]\u001b[0m Trial 175 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4170, 'multi_class': 'multinomial', 'C': 96.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:31,586]\u001b[0m Trial 176 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4860, 'multi_class': 'multinomial', 'C': 97.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:31,989]\u001b[0m Trial 177 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4790, 'multi_class': 'multinomial', 'C': 97.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:32,454]\u001b[0m Trial 178 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4500, 'multi_class': 'multinomial', 'C': 99.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:32,788]\u001b[0m Trial 179 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 4380, 'multi_class': 'ovr', 'C': 99.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:33,240]\u001b[0m Trial 180 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5710, 'multi_class': 'multinomial', 'C': 83.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:33,675]\u001b[0m Trial 181 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5620, 'multi_class': 'multinomial', 'C': 84.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:34,116]\u001b[0m Trial 182 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5250, 'multi_class': 'multinomial', 'C': 84.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:34,606]\u001b[0m Trial 183 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5080, 'multi_class': 'multinomial', 'C': 87.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:35,072]\u001b[0m Trial 184 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4960, 'multi_class': 'multinomial', 'C': 95.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:35,495]\u001b[0m Trial 185 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5280, 'multi_class': 'multinomial', 'C': 92.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:35,995]\u001b[0m Trial 186 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5390, 'multi_class': 'multinomial', 'C': 92.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:36,427]\u001b[0m Trial 187 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5830, 'multi_class': 'multinomial', 'C': 86.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:36,841]\u001b[0m Trial 188 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5960, 'multi_class': 'multinomial', 'C': 86.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:37,255]\u001b[0m Trial 189 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5800, 'multi_class': 'multinomial', 'C': 89.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:37,703]\u001b[0m Trial 190 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5500, 'multi_class': 'multinomial', 'C': 88.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:38,131]\u001b[0m Trial 191 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7080, 'multi_class': 'multinomial', 'C': 89.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:38,521]\u001b[0m Trial 192 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6440, 'multi_class': 'multinomial', 'C': 86.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:38,992]\u001b[0m Trial 193 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6900, 'multi_class': 'multinomial', 'C': 83.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:39,501]\u001b[0m Trial 194 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1220, 'multi_class': 'multinomial', 'C': 88.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:39,974]\u001b[0m Trial 195 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 6770, 'multi_class': 'multinomial', 'C': 77.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:40,232]\u001b[0m Trial 196 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 1490, 'multi_class': 'auto', 'C': 59.300000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:40,479]\u001b[0m Trial 197 finished with value: 0.775497512437811 and parameters: {'class_weight': None, 'max_iter': 1700, 'multi_class': 'ovr', 'C': 26.500000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:40,914]\u001b[0m Trial 198 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1030, 'multi_class': 'multinomial', 'C': 81.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:41,362]\u001b[0m Trial 199 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6210, 'multi_class': 'multinomial', 'C': 82.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:41,800]\u001b[0m Trial 200 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6250, 'multi_class': 'multinomial', 'C': 89.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:42,243]\u001b[0m Trial 201 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6990, 'multi_class': 'multinomial', 'C': 84.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:42,842]\u001b[0m Trial 202 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6470, 'multi_class': 'multinomial', 'C': 85.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:43,457]\u001b[0m Trial 203 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2030, 'multi_class': 'multinomial', 'C': 82.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:44,030]\u001b[0m Trial 204 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1420, 'multi_class': 'multinomial', 'C': 79.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:44,523]\u001b[0m Trial 205 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1240, 'multi_class': 'multinomial', 'C': 83.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:45,395]\u001b[0m Trial 206 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 830, 'multi_class': 'multinomial', 'C': 81.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:46,192]\u001b[0m Trial 207 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 610, 'multi_class': 'multinomial', 'C': 79.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:46,822]\u001b[0m Trial 208 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 230, 'multi_class': 'multinomial', 'C': 86.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:47,523]\u001b[0m Trial 209 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5940, 'multi_class': 'multinomial', 'C': 83.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:35:48,173]\u001b[0m Trial 210 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 390, 'multi_class': 'multinomial', 'C': 83.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:48,792]\u001b[0m Trial 211 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7590, 'multi_class': 'multinomial', 'C': 79.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:49,430]\u001b[0m Trial 212 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1070, 'multi_class': 'multinomial', 'C': 79.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:50,056]\u001b[0m Trial 213 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 7700, 'multi_class': 'multinomial', 'C': 75.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:50,444]\u001b[0m Trial 214 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 7910, 'multi_class': 'ovr', 'C': 88.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:51,053]\u001b[0m Trial 215 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4640, 'multi_class': 'multinomial', 'C': 95.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:51,576]\u001b[0m Trial 216 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2220, 'multi_class': 'multinomial', 'C': 87.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:52,056]\u001b[0m Trial 217 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2170, 'multi_class': 'multinomial', 'C': 90.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:52,583]\u001b[0m Trial 218 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2710, 'multi_class': 'multinomial', 'C': 90.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:53,129]\u001b[0m Trial 219 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 400, 'multi_class': 'multinomial', 'C': 81.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:53,711]\u001b[0m Trial 220 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1680, 'multi_class': 'multinomial', 'C': 80.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:54,177]\u001b[0m Trial 221 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7880, 'multi_class': 'multinomial', 'C': 78.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:54,640]\u001b[0m Trial 222 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1870, 'multi_class': 'multinomial', 'C': 80.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:55,123]\u001b[0m Trial 223 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 3620, 'multi_class': 'multinomial', 'C': 76.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:55,569]\u001b[0m Trial 224 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8360, 'multi_class': 'multinomial', 'C': 97.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:55,925]\u001b[0m Trial 225 finished with value: 0.7748756218905473 and parameters: {'class_weight': None, 'max_iter': 1760, 'multi_class': 'multinomial', 'C': 11.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:56,205]\u001b[0m Trial 226 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8390, 'multi_class': 'ovr', 'C': 93.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:56,671]\u001b[0m Trial 227 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8600, 'multi_class': 'multinomial', 'C': 92.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:57,105]\u001b[0m Trial 228 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1560, 'multi_class': 'multinomial', 'C': 93.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:57,568]\u001b[0m Trial 229 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3400, 'multi_class': 'multinomial', 'C': 84.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:58,099]\u001b[0m Trial 230 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2600, 'multi_class': 'multinomial', 'C': 81.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:58,665]\u001b[0m Trial 231 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3040, 'multi_class': 'multinomial', 'C': 98.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:59,196]\u001b[0m Trial 232 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3130, 'multi_class': 'multinomial', 'C': 97.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:35:59,605]\u001b[0m Trial 233 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 5140, 'multi_class': 'auto', 'C': 98.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:00,099]\u001b[0m Trial 234 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5070, 'multi_class': 'multinomial', 'C': 95.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:00,582]\u001b[0m Trial 235 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8710, 'multi_class': 'multinomial', 'C': 91.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:01,034]\u001b[0m Trial 236 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 8920, 'multi_class': 'multinomial', 'C': 41.800000000000004}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:01,478]\u001b[0m Trial 237 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8770, 'multi_class': 'multinomial', 'C': 94.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:01,908]\u001b[0m Trial 238 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2740, 'multi_class': 'multinomial', 'C': 91.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:02,447]\u001b[0m Trial 239 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2860, 'multi_class': 'multinomial', 'C': 95.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:02,939]\u001b[0m Trial 240 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 2940, 'multi_class': 'multinomial', 'C': 92.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:03,384]\u001b[0m Trial 241 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 8070, 'multi_class': 'multinomial', 'C': 94.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:03,868]\u001b[0m Trial 242 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3710, 'multi_class': 'multinomial', 'C': 96.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:04,302]\u001b[0m Trial 243 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3800, 'multi_class': 'multinomial', 'C': 96.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:04,752]\u001b[0m Trial 244 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3950, 'multi_class': 'multinomial', 'C': 93.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:36:05,204]\u001b[0m Trial 245 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4180, 'multi_class': 'multinomial', 'C': 91.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:05,646]\u001b[0m Trial 246 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3510, 'multi_class': 'multinomial', 'C': 94.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:06,145]\u001b[0m Trial 247 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 3930, 'multi_class': 'multinomial', 'C': 99.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:06,419]\u001b[0m Trial 248 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 3260, 'multi_class': 'ovr', 'C': 97.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:06,862]\u001b[0m Trial 249 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5000, 'multi_class': 'multinomial', 'C': 96.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:07,309]\u001b[0m Trial 250 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4510, 'multi_class': 'multinomial', 'C': 97.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:07,740]\u001b[0m Trial 251 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4830, 'multi_class': 'multinomial', 'C': 97.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:08,156]\u001b[0m Trial 252 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4240, 'multi_class': 'multinomial', 'C': 99.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:08,704]\u001b[0m Trial 253 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5360, 'multi_class': 'multinomial', 'C': 100.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:09,027]\u001b[0m Trial 254 finished with value: 0.7792288557213931 and parameters: {'class_weight': None, 'max_iter': 5500, 'multi_class': 'ovr', 'C': 99.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:09,498]\u001b[0m Trial 255 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6750, 'multi_class': 'multinomial', 'C': 86.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:09,888]\u001b[0m Trial 256 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5720, 'multi_class': 'multinomial', 'C': 87.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:10,308]\u001b[0m Trial 257 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5680, 'multi_class': 'multinomial', 'C': 87.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:10,774]\u001b[0m Trial 258 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5690, 'multi_class': 'multinomial', 'C': 88.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:11,197]\u001b[0m Trial 259 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4710, 'multi_class': 'multinomial', 'C': 94.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:11,623]\u001b[0m Trial 260 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4450, 'multi_class': 'multinomial', 'C': 97.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:12,044]\u001b[0m Trial 261 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4880, 'multi_class': 'multinomial', 'C': 96.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:12,446]\u001b[0m Trial 262 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5210, 'multi_class': 'multinomial', 'C': 95.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:12,758]\u001b[0m Trial 263 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 6060, 'multi_class': 'auto', 'C': 83.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:13,026]\u001b[0m Trial 264 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 6170, 'multi_class': 'ovr', 'C': 90.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:13,458]\u001b[0m Trial 265 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6860, 'multi_class': 'multinomial', 'C': 84.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:13,926]\u001b[0m Trial 266 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5220, 'multi_class': 'multinomial', 'C': 92.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:14,373]\u001b[0m Trial 267 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5350, 'multi_class': 'multinomial', 'C': 96.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:14,904]\u001b[0m Trial 268 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4740, 'multi_class': 'multinomial', 'C': 91.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:15,502]\u001b[0m Trial 269 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4910, 'multi_class': 'multinomial', 'C': 92.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:15,986]\u001b[0m Trial 270 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 4510, 'multi_class': 'multinomial', 'C': 92.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:16,395]\u001b[0m Trial 271 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5090, 'multi_class': 'multinomial', 'C': 85.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:16,781]\u001b[0m Trial 272 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5450, 'multi_class': 'multinomial', 'C': 86.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:17,192]\u001b[0m Trial 273 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5520, 'multi_class': 'multinomial', 'C': 89.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:17,621]\u001b[0m Trial 274 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5290, 'multi_class': 'multinomial', 'C': 89.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:17,918]\u001b[0m Trial 275 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 690, 'multi_class': 'ovr', 'C': 83.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:18,333]\u001b[0m Trial 276 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 1290, 'multi_class': 'multinomial', 'C': 93.5}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:18,760]\u001b[0m Trial 277 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7050, 'multi_class': 'multinomial', 'C': 86.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:19,191]\u001b[0m Trial 278 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5880, 'multi_class': 'multinomial', 'C': 89.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:19,600]\u001b[0m Trial 279 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5590, 'multi_class': 'multinomial', 'C': 85.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-13 21:36:20,054]\u001b[0m Trial 280 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6450, 'multi_class': 'multinomial', 'C': 84.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:20,501]\u001b[0m Trial 281 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5190, 'multi_class': 'multinomial', 'C': 87.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:20,939]\u001b[0m Trial 282 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5790, 'multi_class': 'multinomial', 'C': 87.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:21,204]\u001b[0m Trial 283 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 5550, 'multi_class': 'ovr', 'C': 89.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:21,667]\u001b[0m Trial 284 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 1110, 'multi_class': 'multinomial', 'C': 78.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:21,939]\u001b[0m Trial 285 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 470, 'multi_class': 'auto', 'C': 81.6}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:22,340]\u001b[0m Trial 286 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 310, 'multi_class': 'multinomial', 'C': 79.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:22,780]\u001b[0m Trial 287 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5940, 'multi_class': 'multinomial', 'C': 83.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:23,194]\u001b[0m Trial 288 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6250, 'multi_class': 'multinomial', 'C': 85.3}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:23,614]\u001b[0m Trial 289 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6320, 'multi_class': 'multinomial', 'C': 84.2}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:24,043]\u001b[0m Trial 290 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6600, 'multi_class': 'multinomial', 'C': 83.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:24,445]\u001b[0m Trial 291 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6070, 'multi_class': 'multinomial', 'C': 85.8}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:24,858]\u001b[0m Trial 292 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 5800, 'multi_class': 'multinomial', 'C': 84.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:25,140]\u001b[0m Trial 293 finished with value: 0.7786069651741294 and parameters: {'class_weight': None, 'max_iter': 5420, 'multi_class': 'ovr', 'C': 86.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:25,575]\u001b[0m Trial 294 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 7860, 'multi_class': 'multinomial', 'C': 78.0}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:26,018]\u001b[0m Trial 295 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7520, 'multi_class': 'multinomial', 'C': 80.7}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:26,473]\u001b[0m Trial 296 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6240, 'multi_class': 'multinomial', 'C': 82.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:26,940]\u001b[0m Trial 297 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 6380, 'multi_class': 'multinomial', 'C': 87.4}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:27,366]\u001b[0m Trial 298 finished with value: 0.7810945273631841 and parameters: {'class_weight': None, 'max_iter': 7050, 'multi_class': 'multinomial', 'C': 84.9}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n",
      "\u001b[32m[I 2022-10-13 21:36:27,800]\u001b[0m Trial 299 finished with value: 0.7804726368159205 and parameters: {'class_weight': None, 'max_iter': 7270, 'multi_class': 'multinomial', 'C': 75.1}. Best is trial 1 with value: 0.7810945273631842.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(lambda trial: objective_lr(trial, X_train_vector,y_train), n_trials=300,  gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'max_iter': 5110, 'multi_class': 'ovr', 'C': 75.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params=study.best_params\n",
    "tuned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=75.0, class_weight='balanced', max_iter=5110,\n",
       "                   multi_class='ovr')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  325   63\n",
       "1   64  340"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       388\n",
      "           1       0.84      0.84      0.84       404\n",
      "\n",
      "    accuracy                           0.84       792\n",
      "   macro avg       0.84      0.84      0.84       792\n",
      "weighted avg       0.84      0.84      0.84       792\n",
      "\n",
      "0.9177969021128916\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(**tuned_params)\n",
    "lr.fit(X_train_vector, y_train)\n",
    "\n",
    "X_test_vector = tfidf.transform(X_test)\n",
    "lr_predictions = lr.predict(X_test_vector)\n",
    "\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test,lr_predictions), \n",
    "             index=['0','1'], columns=['0','1'])\n",
    "\n",
    "print(metrics.classification_report(y_test,lr_predictions))\n",
    "print(metrics.roc_auc_score(y_test,lr.predict_proba(X_test_vector)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning has further increased AUC from 0.9063 to 0.9178 and accuracy/F1 scores have increased from 0.81 to 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating pipeline with Tfidvectorizer, logistic regression to run cross validation \n",
    "#to ensure no data leakage\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifier = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(1, 2))), \n",
    "                       ('lr', LogisticRegression(**tuned_params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82157676, 0.82700422, 0.86307054, 0.87136929, 0.86178862,\n",
       "       0.87903226, 0.83404255, 0.88163265, 0.76851852, 0.75      ])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.84 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(corpus2)\n",
    "y = df_train['Polarity']\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10,scoring = \"f1\")\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"f1 score: %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82083333, 0.82916667, 0.8625    , 0.87083333, 0.85833333,\n",
       "       0.875     , 0.8375    , 0.87916667, 0.79166667, 0.775     ])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.84 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(corpus2)\n",
    "y = df_train['Polarity']\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10,scoring = \"accuracy\")\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91412598, 0.91332731, 0.94089867, 0.93923189, 0.9526356 ,\n",
       "       0.9434683 , 0.91395236, 0.95276466, 0.85871075, 0.83731592])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.92 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(corpus2)\n",
    "y = df_train['Polarity']\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10,scoring = \"roc_auc\")\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"ROC_AUC: %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81355932, 0.73846154, 0.85714286, 0.69565217, 0.83076923,\n",
       "       0.79365079, 0.70769231, 0.81355932, 0.83870968, 0.77419355])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.79 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "unseentext = list(df_test['Sentence'])\n",
    "\n",
    "corpus3 = []\n",
    "\n",
    "for x in range(len(unseentext)):\n",
    "    r = re.sub('[^a-zA-Z]', ' ', unseentext[x])\n",
    "    r = r.lower()\n",
    "    r = r.split()\n",
    "    r = ' '.join(r)\n",
    "    corpus3.append(r)\n",
    "\n",
    "\n",
    "X = np.array(corpus3)\n",
    "y = df_test['Polarity']\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10,scoring = \"f1\")\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"f1 score: %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81666667, 0.71666667, 0.83333333, 0.65      , 0.81666667,\n",
       "       0.78333333, 0.68333333, 0.81666667, 0.83333333, 0.76666667])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.77 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(corpus3)\n",
    "y = df_test['Polarity']\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10,scoring = \"accuracy\")\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88950893, 0.8359375 , 0.86941964, 0.81979978, 0.87541713,\n",
       "       0.80311457, 0.75973304, 0.88987764, 0.90211346, 0.85873192])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.85 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(corpus3)\n",
    "y = df_test['Polarity']\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=10,scoring = \"roc_auc\")\n",
    "\n",
    "scores\n",
    "\n",
    "print(\"ROC_AUC: %0.2f (+/- %0.2f)\" % (scores.mean(),scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence in and Review of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the accuracy, F1 score and ROC AUC scores are acceptably high for the training dataset and testing dataset, the standard deviation of the mean of these scores is also high, as shown above. This represents inconsistency in the performance of the model and in terms of the business point of view, this entails risk in deploying the model.\n",
    "\n",
    "Similarly, all testing scores decreased from the training scores by about 6-7% when using the test dataset, meaning that there is some level of overfitting of the model on the training dataset.\n",
    "\n",
    "Keeping these observations in mind, it would be better to try other (deep learning) algorithms and text preprocessing steps (such as spell checks) to attempt to improve the model further, mainly focusing on consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a deeper look in the model - trying to understand why some predictions are incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will first extract the list of False Negative and False Positive sentences into a table to observe them manually in an attempt to identify any patterns. We will then also tokenize the words of these sentences and plot individual graphs to see if there is a high recurring word in any of the two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                0\n",
      "0   cheap but hey it works was pleasantly suprised given the low cost of this item                                                                                               \n",
      "1   talk about great customer service of course we will be back                                                                                                                  \n",
      "2   conclusion very filling meals                                                                                                                                                \n",
      "3   a good quality bargain i bought this after i bought a cheapy from big lots that sounded awful and people on the other end couldn t hear me                                   \n",
      "4   yes this film does require a rather significant amount of puzzle solving but the pieces fit together to create a beautiful picture                                           \n",
      "5   a usable keyboard actually turns a pda into a real world useful machine instead of just a neat gadget                                                                        \n",
      "6   if you re not familiar check it out                                                                                                                                          \n",
      "7   there are massive levels massive unlockable characters it s just a massive game                                                                                              \n",
      "8   very wind resistant                                                                                                                                                          \n",
      "9   love this place hits the spot when i want something healthy but not lacking in quantity or flavor                                                                            \n",
      "10  everything from acting to cinematography was solid                                                                                                                           \n",
      "11  to summarize the food was incredible nay transcendant but nothing brings me joy quite like the memory of the pneumatic condiment dispenser                                   \n",
      "12  exactly what i wanted                                                                                                                                                        \n",
      "13  because both ears are occupied background is not distracting at all                                                                                                          \n",
      "14  high quality chicken on the chicken caesar salad                                                                                                                             \n",
      "15  the salad had just the right amount of sauce to not over power the scallop which was perfectly cooked                                                                        \n",
      "16  the only thing i did like was the prime rib and dessert section                                                                                                              \n",
      "17  five star plus plus                                                                                                                                                          \n",
      "18  the veggitarian platter is out of this world                                                                                                                                 \n",
      "19  the battery is working well as a replacement for the original that came with the phone over years ago                                                                        \n",
      "20  i promise they won t disappoint                                                                                                                                              \n",
      "21  if there was ever a movie that needed word of mouth to promote this is it                                                                                                    \n",
      "22  my mother and brother had to do this when i saw robert ryan portraying this type of man it was a very good imitation of this type of individual and i was impressed          \n",
      "23  everyone is treated equally special                                                                                                                                          \n",
      "24  yet i enjoy watching it                                                                                                                                                      \n",
      "25  very satisifed with that                                                                                                                                                     \n",
      "26  the food came out at a good pace                                                                                                                                             \n",
      "27  these are the nicest restaurant owners i ve ever come across                                                                                                                 \n",
      "28  the owner used to work at nobu so this place is really similar for half the price                                                                                            \n",
      "29  manna from heaven is a terrific film that is both predictable and unpredictable at the same time                                                                             \n",
      "30  you get extra minutes so that you can carry out the call and not get cut off                                                                                                 \n",
      "31  it s like a really sexy party in your mouth where you re outrageously flirting with the hottest person at the party                                                          \n",
      "32  not only did the software do a great job of this i could also make my own ringtones form my existing cds without an internet connection                                      \n",
      "33  good protection and does not make phone too bulky                                                                                                                            \n",
      "34  it s hard not to fall head over heels in love with that girl                                                                                                                 \n",
      "35  the pairing of the two devices was so easy it barely took a couple minutes before i started making calls with the voice dialing feature                                      \n",
      "36  it was just not a fun experience                                                                                                                                             \n",
      "37  this was such an awesome movie that i bought it off of ebay                                                                                                                  \n",
      "38  i tried the cape cod ravoli chicken with cranberry mmmm                                                                                                                      \n",
      "39  in fact it s hard to remember that the part of ray charles is being acted and not played by the man himself                                                                  \n",
      "40  what i really like there is the crepe station                                                                                                                                \n",
      "41  gets a signal when other verizon phones won t                                                                                                                                \n",
      "42  oct                                                                                                                                                                          \n",
      "43  i thoroughly enjoyed it when christopher eccleston took control of the tardis and the continuation of the series                                                             \n",
      "44  does everything it should and more                                                                                                                                           \n",
      "45  i d say that would be the hardest decision honestly all of m s dishes taste how they are supposed to taste amazing                                                           \n",
      "46  totally believable                                                                                                                                                           \n",
      "47  i ordered the voodoo pasta and it was the first time i d had really excellent pasta since going gluten free several years ago                                                \n",
      "48  black water is a thriller that manages to completely transcend it s limitations it s an indie flick by continually subverting expectations to emerge as an intense experience\n",
      "49  i have yet to run this new battery below two bars and that s three days without charging                                                                                     \n",
      "50  it ll be a regular stop on my trips to phoenix                                                                                                                               \n",
      "51  i m glad i found this product on amazon it is hard to find it wasn t high priced                                                                                             \n",
      "52  actually the graphics were good at the time                                                                                                                                  \n",
      "53  plus it s only bucks                                                                                                                                                         \n",
      "54  the only redeeming quality of the restaurant was that it was very inexpensive                                                                                                \n",
      "55  nicest chinese restaurant i ve been in a while                                                                                                                               \n",
      "56  i don t know exactly what it is about this movie but we latched on to this endearing movie and it has become a special part of our family s memories                         \n",
      "57  waste your money on this game                                                                                                                                                \n",
      "58  it features an outlandish array of memorable psychotic but lovable nuts                                                                                                      \n",
      "59  just what i wanted                                                                                                                                                           \n",
      "60  spoilers whatever else can or can t be said about it surface is superbly crafted                                                                                             \n",
      "61  we had a group of when we claimed we would only have and they handled us beautifully                                                                                         \n",
      "62  the portion was huge                                                                                                                                                         \n",
      "63  it is so small and you don t even realize that it is there after a while of getting used to it                                                                               \n"
     ]
    }
   ],
   "source": [
    "#'False Negative' instances as per final results on trained dataset\n",
    "\n",
    "FN = X_test[(y_test == 1) & (lr_predictions == 0)]\n",
    "FN= pd.DataFrame(FN)\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.max_colwidth', -1,\n",
    "                       ):\n",
    "    print(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                             0\n",
      "0   i find this inexcusable and so will probably be returning this phone and perhaps changing carriers                                                                        \n",
      "1   very displeased                                                                                                                                                           \n",
      "2   seems like a good quick place to grab a bite of some familiar pub food but do yourself a favor and look elsewhere                                                         \n",
      "3   you can t relate with them hell you barely can understand them                                                                                                            \n",
      "4   i put the latest os on it v g and it now likes to slow to a crawl and lock up every once in a while                                                                       \n",
      "5   and the drinks are weak people                                                                                                                                            \n",
      "6   i have had problems wit hit dropping signal and more                                                                                                                      \n",
      "7   the cable looks so thin and flimsy it is scary                                                                                                                            \n",
      "8   i m translating movies for a living and this is the first movie in my year working experience that i found offensive to my intelligence                                   \n",
      "9   i m super pissd                                                                                                                                                           \n",
      "10  i bought this phone as a replacement for my startac and have regretted it since                                                                                           \n",
      "11  on the ground right next to our table was a large smeared been stepped in and tracked everywhere pile of green bird poop                                                  \n",
      "12  i hate to disagree with my fellow yelpers but my husband and i were so disappointed with this place                                                                       \n",
      "13  also i feel like the chips are bought not made in house                                                                                                                   \n",
      "14  it is shameful                                                                                                                                                            \n",
      "15  the scallop dish is quite appalling for value as well                                                                                                                     \n",
      "16  i consider this theft                                                                                                                                                     \n",
      "17  i ll even say it again this is torture                                                                                                                                    \n",
      "18  essentially you can forget microsoft s tech support                                                                                                                       \n",
      "19  we ve have gotten a much better service from the pizza place next door than the services we received from this restaurant                                                 \n",
      "20  this is definitely one of the bad ones                                                                                                                                    \n",
      "21  one more thing i can tolerate political incorrectness very well i m all for artistic freedom and suspension of disbelief but the slavic female character was just too much\n",
      "22  this is so embarassing and also my ears hurt if i try to push the ear plug into my ear                                                                                    \n",
      "23  the characters were very stagey and the storyline was a lot like a stage farce                                                                                            \n",
      "24  long whiny and pointless                                                                                                                                                  \n",
      "25  any grandmother can make a roasted chicken better than this one                                                                                                           \n",
      "26  trying to make a call on these is an exercise in frustration                                                                                                              \n",
      "27  i ve lived here since and this was the first and last time i ve stepped foot into this place                                                                              \n",
      "28  now i am getting angry and i want my damn pho                                                                                                                             \n",
      "29  it also had a new problem                                                                                                                                                 \n",
      "30  i am far from a sushi connoisseur but i can definitely tell the difference between good food and bad food and this was certainly bad food                                 \n",
      "31  the food wasn t good                                                                                                                                                      \n",
      "32  i also didn t like the on button it felt like it would crack with use                                                                                                     \n",
      "33  the ambiance isn t much better                                                                                                                                            \n",
      "34  as for the mains also uninspired                                                                                                                                          \n",
      "35  this is a disgrace                                                                                                                                                        \n",
      "36  i go to far too many places and i ve never seen any restaurant that serves a egg breakfast especially for                                                                 \n",
      "37  the potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer                                                            \n",
      "38  very little music or anything to speak of                                                                                                                                 \n",
      "39  i bought these hoping i could make my bluetooth headset fit better but these things made it impossible to wear                                                            \n",
      "40  utterly without merit on any level this is akin to torture                                                                                                                \n",
      "41  my husband and i ate lunch here and were very disappointed with the food and service                                                                                      \n",
      "42  it was a pale color instead of nice and char and has no flavor                                                                                                            \n",
      "43  sadly gordon ramsey s steak is a place we shall sharply avoid during our next trip to vegas                                                                               \n",
      "44  the phone gets extremely hot                                                                                                                                              \n",
      "45  i dressed up to be treated so rudely                                                                                                                                      \n",
      "46  so in a nutshell the restaraunt smells like a combination of a dirty fish market and a sewer                                                                              \n",
      "47  nobody identifies with these characters because they re all cardboard cutouts and stereotypes or predictably reverse stereotypes                                          \n",
      "48  if you check the director s filmography on this site you will see why this film didn t have a chance                                                                      \n",
      "49  it is cheap and it feel and look just as cheap                                                                                                                            \n",
      "50  the selection of food was not the best                                                                                                                                    \n",
      "51  the kids are annoying                                                                                                                                                     \n",
      "52  i asked multiple times for the wine list and after some time of being ignored i went to the hostess and got one myself                                                    \n",
      "53  my experience was terrible this was my fourth bluetooth headset and while it was much more comfortable than my last jabra which i hated                                   \n",
      "54  say bye bye to your tip lady                                                                                                                                              \n",
      "55  oh and i forgot to also mention the weird color effect it has on your phone                                                                                               \n",
      "56  unfortunately it s easy to accidentally activate them with the gentle touch buttons if you accidentally touch the phone to your face while listening                      \n",
      "57  this was like the final blow                                                                                                                                              \n",
      "58  this item worked great but it broke after months of use                                                                                                                   \n",
      "59  you also cannot take pictures with it in the case because the lense is covered                                                                                            \n",
      "60  it s this pandering to the audience that sabotages most of his films                                                                                                      \n",
      "61  all in all a great disappointment                                                                                                                                         \n",
      "62  i have watched their prices inflate portions get smaller and management attitudes grow rapidly                                                                            \n"
     ]
    }
   ],
   "source": [
    "#'False Positive' instances as per final results on trained dataset\n",
    "\n",
    "FP = X_test[(y_test == 0) & (lr_predictions == 1)]\n",
    "FP= pd.DataFrame(FP)\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.max_colwidth', -1,\n",
    "                       ):\n",
    "    print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='frequency', ylabel='word'>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAAHgCAYAAAD5QXNjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzzElEQVR4nO3de7xcdX3v/9dbLgZIIECAesGmXCwFCrFsL0Hgh0dqwUuVS+sFewRt97HgL6JHre3PtljrOZyflFZbq91SAZXaVhBQVMCjRRBB2YEQQLSoxGpVKJAAAQy3z/ljL07HuJNsksxes2Zez8cjj71mzXeteY/rMdZ3v99Zk6pCkiRJkjS6ntR2AEmSJElSuyyGkiRJkjTiLIaSJEmSNOIshpIkSZI04iyGkiRJkjTiLIaSJEmSNOK2bDvAbFqwYEEtXLiw7RiSJEmS1IqlS5feWVW7rL1/pIrh07fbni+84ZS2Y0iSJEkaUrv8/mvbjrBeSb4/3X6XkkqSJEnSiBu4YphkfpKTmu3Dk1zcdiZJkiRJGmYDVwyB+cBJbYeQJEmSpFExiN8xPA3YM8ky4GHg/iTnAfsDS4HXVlUlOQg4A5gL3AmcUFU/bimzJEmSJHXWIM4YvhP4blUtAt4OPAs4BdgX2AN4fpKtgL8Gjquqg4CPAu9tJa0kSZIkddwgzhiu7RtV9UOAZhZxIbCKqRnELyYB2AKYdrYwyTgwDvD0nXbue1hJkiRJ6pouFMM1PduPMpU5wM1VtXhDB1fVBDABsOgX96i+JJQkSZKkDhvEpaT3AfM2MObbwC5JFgMk2SrJfn1PJkmSJElDaOBmDKvqriRXJbkJeBC4fZoxDyU5DvhAkh2Yeh9/Bdw8q2ElSZIkaQgMXDEEqKrXrGP/m3q2lwGHzVYmSZIkSRpWg7iUVJIkSZI0iwZyxrBfttxlJ3b5/de2HUOSJEmSBoozhpIkSZI04iyGkiRJkjTiRmop6SP/cQd3fPgDbceQJEkDbNc3Lmk7giTNOmcMJUmSJGnEWQwlSZIkacRZDCVJkiRpxHW6GCa5MMnSJDcnGW87jyRJkiR1UddvPvP6qro7yTbAtUnOr6q72g4lSZIkSV3S6RlDYEmSG4BrgN2BvdcekGQ8yWSSybtWr571gJIkSZI06DpbDJMcDhwBLK6qA4HrgTlrj6uqiaoaq6qxnefOnd2QkiRJktQBnS2GwA7Ayqp6IMk+wPPaDiRJkiRJXdTlYngJsGWS5cB7mFpOKkmSJEl6gjp785mqWgMc1XYOSZIkSeq6zhbDjbHlLruy6xuXtB1DkiRJkgZKl5eSSpIkSZI2A4uhJEmSJI24kVpK+vAdP+BHH3xr2zEkSdIAe+rJZ7QdQZJmnTOGkiRJkjTihqIYJlmS5JYk57adRZIkSZK6ZliWkp4EHFVVt7UdRJIkSZK6pnMzhknemuSm5t8pST4M7AF8Jslb2s4nSZIkSV3TqRnDJAcBJwLPBQJ8HXgtcCTwgqq6s8V4kiRJktRJnSqGwCHABVV1P0CSTwOHru+AJOPAOMDTdpzX94CSJEmS1DVdW0qaJ3pAVU1U1VhVje08d5t+ZJIkSZKkTutaMbwCeEWSbZNsBxwNXNlyJkmSJEnqtE4tJa2q65KcDXyj2XVmVV2fPOGJREmSJElSo1PFEKCqzgDOWGvfwnbSSJIkSVL3dW0pqSRJkiRpM+vcjOGm2GrX3XnqyWdseKAkSZIkjRBnDCVJkiRpxFkMJUmSJGnEjdRS0p/e8R2+9cGXtx1DkqSRsM/JF7UdQZI0Q84YSpIkSdKI62wxTPK15u/CJK9pO48kSZIkdVVni2FVHdxsLgQshpIkSZK0kTpbDJOsbjZPAw5NsizJW9rMJEmSJEldNAw3n3kn8LaqemnbQSRJkiSpizo7YzhTScaTTCaZXLn6obbjSJIkSdLAGfpiWFUTVTVWVWM7zt267TiSJEmSNHCGoRjeB8xrO4QkSZIkddUwFMPlwCNJbvDmM5IkSZL0xHX25jNVNbf5+zDwwpbjSJIkSVJndbYYbow5u+7FPidf1HYMSZIkSRoow7CUVJIkSZK0CSyGkiRJkjTiRmop6f3/8R2unnhp2zEkSS1aPH5x2xEkSRo4zhhKkiRJ0ogbmmKY5GttZ5AkSZKkLhqaYlhVB7edQZIkSZK6aGiKYZLVbWeQJEmSpC4ammIoSZIkSdo4Q18Mk4wnmUwyuXL1Q23HkSRJkqSBM/TFsKomqmqsqsZ2nLt123EkSZIkaeAMfTGUJEmSJK2fxVCSJEmSRtzQFMOqmtt2BkmSJEnqoqEphpIkSZKkjbNl2wFm03a77MXi8YvbjiFJkiRJA8UZQ0mSJEkacRZDSZIkSRpxI7WU9N47b+XSv39x2zEkSRvwG2/4fNsRJEkaKc4YSpIkSdKI62QxTPK1tjNIkiRJ0rDoZDGsqoPbziBJkiRJw6KTxTDJ6ubvU5JckWRZkpuSHNp2NkmSJEnqmq7ffOY1wKVV9d4kWwDbth1IkiRJkrqm68XwWuCjSbYCLqyqZWsPSDIOjAPsutOc2U0nSZIkSR3QyaWkj6uqK4DDgH8HPp7kv04zZqKqxqpqbId5W896RkmSJEkadJ0uhkl+Ebijqj4C/D3way1HkiRJkqTO6fpS0sOBtyd5GFgN/NyMoSRJkiRp/TpZDKtqbvP3HOCcluNIkiRJUqd1shhurO0X7M1vvOHzbceQJEmSpIHS6e8YSpIkSZI2ncVQkiRJkkbcSC0lXXnnrZx31pFtx5AkbcBxJ17SdgRJkkaKM4aSJEmSNOI6UwyTzE9yUts5JEmSJGnYdKYYAvMBi6EkSZIkbWZd+o7hacCeSZYBX2z2HQUU8OdV9U9tBZMkSZKkLuvSjOE7ge9W1SLgGmARcCBwBPC+JE9pL5okSZIkdVeXimGvQ4BPVtWjVXU78BXg2dMNTDKeZDLJ5L2rH5rVkJIkSZLUBV0thpnpwKqaqKqxqhrbfu7W/cwkSZIkSZ3UpWJ4HzCv2b4CeGWSLZLsAhwGfKO1ZJIkSZLUYZ25+UxV3ZXkqiQ3AV8AlgM3MHXzmXdU1U9aDShJkiRJHdWZYghQVa9Za9fbWwkiSZIkSUOkS0tJJUmSJEl90KkZw02144K9Oe7ES9qOIUmSJEkDxRlDSZIkSRpxFkNJkiRJGnEjtZT0zrv+lbPOeVHbMSRJG3Di6y5rO4IkSSPFGUNJkiRJGnEDUwyTzE9yUrN9eJKL1zHuzCT7zm46SZIkSRpeA1MMgfnASRsaVFW/W1Xf7H8cSZIkSRoNg1QMTwP2TLIMeB8wN8l5Sb6V5NwkAUhyeZKxJFskOTvJTUluTPKWNsNLkiRJUlcN0s1n3gnsX1WLkhwOXATsB/wIuAp4PvDVnvGLgKdV1f4wtRR1FrNKkiRJ0tAYpBnDtX2jqn5YVY8By4CFaz3/PWCPJH+d5Ejg3ulOkmQ8yWSSydX3PdzXwJIkSZLURYNcDNf0bD/KWrObVbUSOBC4HDgZOHO6k1TVRFWNVdXY3Hlb9SmqJEmSJHXXIC0lvQ+YN9PBSRYAD1XV+Um+C5zdr2CSJEmSNMwGphhW1V1JrkpyE/AgcPsGDnkacFaSx2c9/7CvASVJkiRpSA1MMQSoqtesY/+berYP73nq1/qdSZIkSZKG3UAVw35bsPMzOfF1l7UdQ5IkSZIGyiDffEaSJEmSNAsshpIkSZI04kZqKekdd9/KB879jbZjSNJQWHL8pW1HkCRJm4kzhpIkSZI04iyGkiRJkjTiLIaSJEmSNOIGohgmeUeSJc32Xyb5crP9wiSfSPKhJJNJbk7y7p7jTkvyzSTLk5zeVn5JkiRJ6rJBufnMFcB/Bz4AjAFPTrIVcAhwJfCpqro7yRbAl5IcAPwQOBrYp6oqyfx2okuSJElStw3EjCGwFDgoyTxgDXA1UwXxUKaK4W8nuQ64HtgP2Be4F/gpcGaSY4AHpjtxkvFmtnFy9b0P9f+dSJIkSVLHDEQxrKqHgRXAicDXmCqDLwD2BB4E3ga8sKoOAD4HzKmqR4DnAOcDrwAuWce5J6pqrKrG5m6/dZ/fiSRJkiR1z0AUw8YVTBXAK5gqhm8ElgHbA/cD9yTZDTgKIMlcYIeq+jxwCrBo1hNLkiRJ0hAYlO8YwlQZ/P+Aq6vq/iQ/Ba6sqhuSXA/cDHwPuKoZPw+4KMkcIMBb2ggtSZIkSV03MMWwqr4EbNXz+Jk92yes47Dn9DmWJEmSJA29QVpKKkmSJElqwcDMGM6GXXfamyXHX9p2DEmSJEkaKM4YSpIkSdKIsxhKkiRJ0ogbqaWkP1p5K6f+82+0HUOShsKpv+3SfEmShoUzhpIkSZI04oaiGCZZ3XYGSZIkSeqqoSiGkiRJkqSNNzDFMMmFSZYmuTnJeLNvdZL3JrkhyTVJdmv2/1KSq5Ncm+Q97SaXJEmSpG4bmGIIvL6qDgLGgCVJdga2A66pqgOBK4Dfa8a+H/hQVT0b+EkraSVJkiRpSAxSMVyS5AbgGmB3YG/gIeDi5vmlwMJm+/nAJ5vtj6/vpEnGk0wmmXzg3oc2e2hJkiRJ6rqBKIZJDgeOABY3s4PXA3OAh6uqmmGP8rM/r1HMQFVNVNVYVY1tu/3Wmy+0JEmSJA2JgSiGwA7Ayqp6IMk+wPM2MP4q4FXN9vF9TSZJkiRJQ25QiuElwJZJlgPvYWo56fq8GTg5ybVMlUpJkiRJ0kbacsND+q+q1gBHTfPU3J4x5wHnNdu3AYt7xp3W14CSJEmSNMQGohjOlqfuuDen/valbceQJEmSpIEyKEtJJUmSJEktsRhKkiRJ0ogbqaWkK1bdyokXHNl2DEn6OWcdfUnbESRJ0ghzxlCSJEmSRlzrxTDJ/CQnNduHJ7n4CR5/QpKn9iedJEmSJA2/1oshMB84aROOPwGwGEqSJEnSRhqE7xieBuyZZBnwMHB/kvOA/YGlwGurqpL8CfAyYBvga8B/A44FxoBzkzwILK6qB1t4D5IkSZLUWYMwY/hO4LtVtQh4O/As4BRgX2AP4PnNuL+pqmdX1f5MlcOXNj96PwkcX1WLLIWSJEmS9MQNQjFc2zeq6odV9RiwDFjY7H9Bkq8nuRH4L8B+MzlZkvEkk0kmf3rvQ30JLEmSJEldNojFcE3P9qPAlknmAH8LHFdVvwp8BJgzk5NV1URVjVXV2Jztt978aSVJkiSp4wahGN4HzNvAmMdL4J1J5gLHPcHjJUmSJEnr0PrNZ6rqriRXJbkJeBC4fZoxq5J8BLgRWAFc2/P02cCHvfmMJEmSJG2c1oshQFW9Zh3739Sz/S7gXdOMOR84v3/pJEmSJGm4DcJSUkmSJElSiwZixnC2LJy/N2cdfUnbMSRJkiRpoDhjKEmSJEkjzmIoSZIkSSNupJaS3rrq3zjqopPbjiGNvC+8/INtR5AkSVIPZwwlSZIkacRZDCVJkiRpxFkMJUmSJGnEdboYJtkuyeeS3JDkpiSvbDuTJEmSJHVN128+cyTwo6p6CUCSHVrOI0mSJEmd0+kZQ+BG4Igk/yvJoVV1z9oDkownmUwy+dC9D7YQUZIkSZIGW6eLYVX9K3AQUwXxfyb5k2nGTFTVWFWNbb39NrOeUZIkSZIGXaeXkiZ5KnB3VX0iyWrghJYjSZIkSVLndLoYAr8KvC/JY8DDwO+3nEeSJEmSOqfTxbCqLgUubTuHJEmSJHVZp4vhE7X3/GfwhZd/sO0YkiRJkjRQOn3zGUmSJEnSprMYSpIkSdKIG6mlpLeu+jEvvuDP244hdcbnj35X2xEkSZI0C5wxlCRJkqQR1/limOSE5vcMJUmSJEkbofPFkKkftbcYSpIkSdJGGrhimGRhkluSfCTJzUkuS7JNkkVJrkmyPMkFSXZMchwwBpybZFmSbdrOL0mSJEldM3DFsLE38MGq2g9YBRwLfAz4g6o6ALgR+NOqOg+YBI6vqkVV9WBbgSVJkiSpqwa1GN5WVcua7aXAnsD8qvpKs+8c4LCZnCjJeJLJJJMP3Xv/5k8qSZIkSR03qMVwTc/2o8D8jT1RVU1U1VhVjW29/XabHEySJEmShs2gFsO13QOsTHJo8/h3gMdnD+8D5rWSSpIkSZKGQJd+4P51wIeTbAt8Dzix2X92s/9BYLHfM5QkSZKkJ2bgimFVrQD273l8es/Tz5tm/PnA+f1PJkmSJEnDqStLSSVJkiRJfTJwM4b9tPf8p/D5o9/VdgxJkiRJGijOGEqSJEnSiLMYSpIkSdKIG6mlpLeuuoOXfPoDbcfQCPrcMUvajiBJkiStkzOGkiRJkjTiOl8Mk8xPclLbOSRJkiSpqzpfDIH5gMVQkiRJkjbSMBTD04A9kyxL8r62w0iSJElS1wzDzWfeCexfVYvaDiJJkiRJXTQMM4brlWQ8yWSSyYfuWd12HEmSJEkaOENfDKtqoqrGqmps6x3mth1HkiRJkgbOMBTD+4B5bYeQJEmSpK7qfDGsqruAq5Lc5M1nJEmSJOmJG4abz1BVr2k7gyRJkiR11VAUw5nae/6ufO6YJW3HkCRJkqSB0vmlpJIkSZKkTWMxlCRJkqQRN1JLSW9deScvOf/MtmNoQH3u2N9tO4IkSZLUCmcMJUmSJGnEWQwlSZIkacRZDCVJkiRpxK33O4ZJ/hqodT1fVbPy2w9J3gq8vnl4JnAh8AXgq8DBwL8DL6+qB2cjjyRJkiQNkw3NGE4CS4E5wK8Btzb/FgGP9jVZI8lBwInAc4HnAb8H7AjsDXywqvYDVgHHzkYeSZIkSRo2650xrKpzAJKcALygqh5uHn8YuKzv6aYcAlxQVfc3r/1p4FDgtqpa1oxZCiyc7uAk48A4wJwFO/U7qyRJkiR1zky/Y/hUYF7P47nNvtmQdexf07P9KOsouVU1UVVjVTW29fbzphsiSZIkSSNtpsXwNOD6JGcnORu4DvgffUv1s64AXpFk2yTbAUcDV87Sa0uSJEnS0NvgD9wneRLwbaa+4/fcZvc7q+on/Qz2uKq6rimj32h2nQmsnI3XliRJkqRRsMFiWFWPJfmLqloMXDQLmabLcAZwxlq79+95/vTZTSRJkiRJw2OmS0kvS3JsknV930+SJEmS1FGpWufPFP7noOQ+YDumbvLy02Z3VdX2fcy22Y2NjdXk5GTbMSRJkiSpFUmWVtXY2vs3uJQUoKq8nackSZIkDakZFUOAJL8JHNY8vLyqLu5PJEmSJEnSbJpRMUxyGvBs4Nxm15uTHFJV7+xbsj74zsq7eel55254oEbSxccd33YESZIkqRUznTF8MbCoqh4DSHIOcD3QqWIoSZIkSfp5M70rKcD8nu0dNnOO/yvJwiQ3PYHxhyc5uF95JEmSJGnYzXTG8H8A1yW5HAhT3zX8w36FeoIOB1YDX2s5hyRJkiR10kxnDF8CfBRYCnwaWFxV/9i3VLBlknOSLE9yXpJtk6xIsgAgyViSy5MsBN4IvCXJsiSH9jGTJEmSJA2lmc4YngUcAvwmsAewLMkVVfX+PuX6ZeANVXVVko8CJ003qKpWJPkwsLqqTu9TFkmSJEkaajP9HcMvJ/kKU3cmfQFTs3T7Af0qhj+oqqua7U8ASzb2REnGgXGAbRbsvBmiSZIkSdJwmenPVXwJ2A64GrgSeHZV3dHHXDXN40f4z6Wvc2Z8oqoJYAJg/p57rH1eSZIkSRp5M/2O4XLgIWB/4ABg/yTb9C0VPCPJ4mb71cBXgRXAQc2+Y3vG3gfM62MWSZIkSRpqMyqGVfWWqjoMOBq4i6nvHK7qY65bgNclWQ7sBHwIeDfw/iRXAo/2jP0scLQ3n5EkSZKkjTPTpaRvAg5lasbu+0zdofTKfgSqqhXAvtM8dSXwzGnG/ytTs5iSJEmSpI0w07uSbgOcASytqkf6mKev9tpxJy4+7vi2Y0iSJEnSQJnpXUnf1+8gkiRJkqR2zPTmM5IkSZKkITXTpaRD4TsrV/Gy8z7ddgwNqM8ed0zbESRJkqRWOGMoSZIkSSNuoIthks8nmd/8O6ln/+FJLm4zmyRJkiQNi4EuhlX14qpaBcwHTlr/aEmSJEnSxmi1GCZ5R5IlzfZfJvlys/3CJJ9IsiLJAuA0YM/mR+wfv0Pq3CTnJflWknOTpKW3IUmSJEmd1vaM4RXAoc32GFNlbyvgEKZ+0P5x7wS+W1WLqurtzb5nAacA+wJ7AM+flcSSJEmSNGTaLoZLgYOSzAPWAFczVRAP5WeL4XS+UVU/rKrHgGXAwukGJRlPMplk8qF779lswSVJkiRpWLRaDKvqYWAFcCLwNabK4AuAPYFbNnD4mp7tR1nHT29U1URVjVXV2Nbb77DJmSVJkiRp2LQ9YwhTy0nf1vy9EngjsKyqqmfMfcC8FrJJkiRJ0tAbhGJ4JfAU4Oqquh34KWstI62qu4CrktzUc/MZSZIkSdJmMO3yy9lUVV8Ctup5/Mye7YU9269Z69DLe557U/8SSpIkSdJwG4QZQ0mSJElSi1qfMZxNe+04n88ed0zbMSRJkiRpoDhjKEmSJEkjzmIoSZIkSSNupJaSfmflvbz8vEvajqEBddFxR7YdQZIkSWqFM4aSJEmSNOI6XwyT/FHbGSRJkiSpyzpfDAGLoSRJkiRtgk59xzDJhcDuwBzg/cAewDZJlgE3V9Xx7aWTJEmSpG7qVDEEXl9VdyfZBrgW+H+AN1XVonZjSZIkSVJ3da0YLklydLO9O7D3hg5IMg6MA2yzYNc+RpMkSZKkburMdwyTHA4cASyuqgOB65laUrpeVTVRVWNVNbb19jv0N6QkSZIkdVBniiGwA7Cyqh5Isg/wvGb/w0m2ajGXJEmSJHVal4rhJcCWSZYD7wGuafZPAMuTnNtaMkmSJEnqsM58x7Cq1gBHTfPU5cAfzG4aSZIkSRoenSmGm8NeO27PRccd2XYMSZIkSRooXVpKKkmSJEnqA4uhJEmSJI24kVpK+t2Vqzn6/K+2HUOb6IJjD2k7giRJkjRUnDGUJEmSpBFnMZQkSZKkEWcxlCRJkqQR14limOTCJEuT3JxkvNm3Osl7k9yQ5Joku7WdU5IkSZK6qBPFEHh9VR0EjAFLkuwMbAdcU1UHAlcAv9dmQEmSJEnqqq4UwyVJbgCuAXYH9gYeAi5unl8KLJzuwCTjSSaTTK65d9UsRJUkSZKkbhn4YpjkcOAIYHEzO3g9MAd4uKqqGfYo6/jpjaqaqKqxqhp78vbz+x9YkiRJkjpm4IshsAOwsqoeSLIP8Ly2A0mSJEnSMOlCMbwE2DLJcuA9TC0nlSRJkiRtJtMuvxwkVbUGOGqap+b2jDkPOG/WQkmSJEnSEOnCjKEkSZIkqY8GfsZwc9pzx7lccOwhbceQJEmSpIHijKEkSZIkjTiLoSRJkiSNuJFaSvq9lQ/yW+cvbzuGNtGnjj2g7QiSJEnSUHHGUJIkSZJG3MAXwyQLk9zUdg5JkiRJGlYDXwwlSZIkSf3VlWK4ZZJzkixPcl6SbZMclOQrSZYmuTTJU9oOKUmSJEld1JVi+MvARFUdANwLnAz8NXBcVR0EfBR4b4v5JEmSJKmzunJX0h9U1VXN9ieAPwL2B76YBGAL4MfTHZhkHBgH2HaBk4qSJEmStLauFMNa6/F9wM1VtXiDB1ZNABMAO+2539rnkSRJkqSR15WlpM9I8ngJfDVwDbDL4/uSbJVkv9bSSZIkSVKHdaUY3gK8LslyYCea7xcC/yvJDcAy4OD24kmSJElSdw38UtKqWgHsO81Ty4DDZjWMJEmSJA2hgS+Gm9MeO27Dp449oO0YkiRJkjRQurKUVJIkSZLUJxZDSZIkSRpxI7WU9AerHmLJBT9oO4Y20QeO3r3tCJIkSdJQccZQkiRJkkbcQBTDJKvbziBJkiRJo2ogiqEkSZIkqT2zUgyTvCPJkmb7L5N8udl+YZJPNNvvTXJDkmuS7Nbs2yXJ+Umubf49v9l/apKPJrk8yfceP7ckSZIk6YmbrRnDK4BDm+0xYG6SrYBDgCuB7YBrqurAZuzvNWPfD/xlVT0bOBY4s+ec+wC/ATwH+NPmfJIkSZKkJ2i27kq6FDgoyTxgDXAdUwXxUGAJ8BBwcc/YX2+2jwD2TfL4ebZvzgHwuapaA6xJcgewG/DDtV84yTgwDjBvl6dt5rclSZIkSd03K8Wwqh5OsgI4EfgasBx4AbAncAvwcFVVM/zRnlxPAhZX1YO952uK4pqeXb3HrP3aE8AEwG57HVDTjZEkSZKkUTabN5+5Anhb8/dK4I3Asp5COJ3LgDc9/iDJon4GlCRJkqRRNJvF8ErgKcDVVXU78NNm3/osAcaSLE/yTabKpCRJkiRpM5qt7xhSVV8Ctup5/Mye7bk92+cB5zXbdwKvnOZcp671eP/Nn1iSJEmSRoO/YyhJkiRJI27WZgwHwe7zt+YDR+/edgxJkiRJGijOGEqSJEnSiLMYSpIkSdKIG6mlpHesepgPXnB72zG0iU4+ere2I0iSJElDxRlDSZIkSRpxnSqGSc5OclzbOSRJkiRpmHSqGEqSJEmSNr/Wi2GStya5qfl3SpKFSW5J8pEkNye5LMk2ax3zwiQX9Dz+9SSfnv30kiRJktR9rRbDJAcBJwLPBZ4H/B6wI7A38MGq2g9YBRy71qFfBn4lyS7N4xOBs2YjsyRJkiQNm7ZnDA8BLqiq+6tqNfBp4FDgtqpa1oxZCizsPaiqCvg48Nok84HFwBeme4Ek40kmk0yuvvfuvrwJSZIkSeqytn+uIuvYv6Zn+1Fgm2nGnAV8Fvgp8KmqemS6E1XVBDAB8Iy9DqyNjypJkiRJw6ntGcMrgFck2TbJdsDRwJUzObCqfgT8CHgXcHbfEkqSJEnSkGt1xrCqrktyNvCNZteZwMoncIpzgV2q6pubO5skSZIkjYq2l5JSVWcAZ6y1e/+e50/v2T5hrXGHAB/pWzhJkiRJGgGtF8ONlWQpcD/w32d6zK7zt+Lko3frXyhJkiRJ6qDOFsOqOqjtDJIkSZI0DNq++YwkSZIkqWWdnTHcGKtWPsKnz7uz7Rgj4ZjjFrQdQZIkSdIMOWMoSZIkSSPOYihJkiRJI66TxTDJFm1nkCRJkqRhMZDFMMmFSZYmuTnJeLNvdZI/S/J1YHGS1yb5RpJlSf7OsihJkiRJG2cgiyHw+ubnKMaAJUl2BrYDbqqq5wJ3Aa8Enl9Vi4BHgePbCitJkiRJXTaodyVdkuToZnt3YG+myt/5zb4XAgcB1yYB2Aa4Y7oTNTOO4wALFjy9j5ElSZIkqZsGrhgmORw4AlhcVQ8kuRyYA/y0qh59fBhwTlX94YbOV1UTwATAXnsuqn5kliRJkqQuG8SlpDsAK5tSuA/wvGnGfAk4LsmuAEl2SvKLsxlSkiRJkobFIBbDS4AtkywH3gNcs/aAqvom8C7gsmbcF4GnzGpKSZIkSRoSA7eUtKrWAEdN89Tctcb9E/BPsxJKkiRJkobYIM4YSpIkSZJm0cDNGPbT/B235JjjFrQdQ5IkSZIGijOGkiRJkjTiLIaSJEmSNOJGainpfXc/wr+c+x9txxgJLzh+l7YjSJIkSZohZwwlSZIkacQNTDFMsjDJTZtw/OrNmUeSJEmSRsXAFENJkiRJUjsG7TuGWyT5CHAw8O/Ay4HXAuPA1sB3gN+pqgeS/BLwD0y9h0tayitJkiRJnTdoM4Z7Ax+sqv2AVcCxwKer6tlVdSBwC/CGZuz7gQ9V1bOBn7QRVpIkSZKGwaAVw9uqalmzvRRYCOyf5MokNwLHA/s1zz8f+GSz/fF1nTDJeJLJJJP33HtXf1JLkiRJUocNWjFc07P9KFPLRM8G3lRVvwq8G5jTM6Y2dMKqmqiqsaoa22H7nTdnVkmSJEkaCoNWDKczD/hxkq2YmjF83FXAq5rt43/uKEmSJEnSjHShGP4x8HXgi8C3eva/GTg5ybXADm0EkyRJkqRhMDB3Ja2qFcD+PY9P73n6Q9OMvw1Y3LPrtL6FkyRJkqQhNjDFcDbM22lLXnD8Lm3HkCRJkqSB0oWlpJIkSZKkPrIYSpIkSdKIG6mlpA/c+QjXn3lH2zFGwrN+d9e2I0iSJEmaIWcMJUmSJGnEdaoYJnljkv/adg5JkiRJGiadWkpaVR9uO4MkSZIkDZu+zRgmWZjkW0nOTHJTknOTHJHkqiS3JnlOkp2SXJhkeZJrkhyQ5ElJViSZ33Ou7yTZLcmpSd7W7NszySVJlia5Msk+/XovkiRJkjTM+r2UdC/g/cABwD7Aa4BDgLcBfwS8G7i+qg5oHn+sqh4DLgKOBkjyXGBFVd2+1rkngP+3qg5qzve3fX4vkiRJkjSU+r2U9LaquhEgyc3Al6qqktwILAR+ETgWoKq+nGTnJDsA/wT8CXAW8Krm8f+VZC5wMPCpJI/vfvJ0AZKMA+MAv7DT0zfrm5MkSZKkYdDvYrimZ/uxnsePNa/9yDTHFHA1sFeSXYBXAH++1pgnAauqatGGAlTVBFOzi+y7cFE9geySJEmSNBLavivpFcDxAEkOB+6sqnurqoALgDOAW6rqrt6Dqupe4LYkv9UcmyQHzmZwSZIkSRoWbRfDU4GxJMuB04DX9Tz3T8BrWWsZaY/jgTckuQG4GXh5H3NKkiRJ0tDq21LSqloB7N/z+IR1PDdtoauqSSBr7Tu1Z/s24MjNFFeSJEmSRlbbM4aSJEmSpJZ16gfuN9W2C7bkWb+7a9sxJEmSJGmgOGMoSZIkSSPOYihJkiRJI26klpI+dPvDrPirn7QdYyQsPOUX2o4gSZIkaYacMZQkSZKkEWcxlCRJkqQRZzGUJEmSpBE3MMUwyXuSvLnn8XuTvDnJ+5LclOTGJK9snjs8ycU9Y/8myQktxJYkSZKkzhuYYgj8PfA6gCRPAl4F/BBYBBwIHAG8L8lT2gooSZIkScNoYO5KWlUrktyV5FnAbsD1wCHAJ6vqUeD2JF8Bng3cO9PzJhkHxgGeuuPTNn9wSZIkSeq4QZoxBDgTOAE4EfgokHWMe4SfzT5nXSesqomqGquqsZ2323lz5ZQkSZKkoTFoxfAC4EimZgUvBa4AXplkiyS7AIcB3wC+D+yb5MlJdgBe2FZgSZIkSeq6gVlKClBVDyX5F2BVVT2a5AJgMXADUMA7quonAEn+GVgO3MrUslNJkiRJ0kYYqGLY3HTmecBvAVRVAW9v/v2MqnoH8I5ZDShJkiRJQ2hgimGSfYGLgQuq6tZ+vMbWu23FwlN+oR+nliRJkqTOGphiWFXfBPZoO4ckSZIkjZpBu/mMJEmSJGmWDcyM4Wx4+PY1/OT077QdYyT8wtv2ajuCJEmSpBlyxlCSJEmSRlzni2GShUluajuHJEmSJHVV54uhJEmSJGnTzPp3DJP8MXA88APgTmAp8L+BDwPbAt8FXl9VK5MsWsf+g4CPAg8AX53t9yBJkiRJw2RWZwyTjAHHAs8CjgHGmqc+BvxBVR0A3Aj86Qb2nwUsqarFs5VdkiRJkobVbC8lPQS4qKoerKr7gM8C2wHzq+orzZhzgMOS7DDD/R9f3wsmGU8ymWTyrtV3b/Y3JEmSJEldN9vFMJvpHDXTwVU1UVVjVTW289ydNsPLS5IkSdJwme1i+FXgZUnmJJkLvAS4H1iZ5NBmzO8AX6mqe9axfxVwT5JDmv3Hz158SZIkSRo+s3rzmaq6NslngBuA7wOTwD3A64APJ9kW+B5wYnPIuvafCHw0yQPApbP4FiRJkiRp6Mz6XUmB06vq1KbsXQH8RVUtA5639sD17F8KHNiz69S+JJUkSZKkEdBGMZxIsi8wBzinqq5rIYMkSZIkqTHrxbCqXjPbr/m4rXZ7Mr/wtr3aenlJkiRJGkizffMZSZIkSdKAsRhKkiRJ0ohr4zuGrXn49ge4/a+Wth1jJOx2ykFtR5AkSZI0Q84YSpIkSdKIG6himORrG3HMK5q7nEqSJEmSNsJAFcOqOngjDnsFYDGUJEmSpI00UMUwyeokhye5uGff3yQ5odk+Lck3kyxPcnqSg4HfBN6XZFmSPVuKLkmSJEmd1ZmbzyTZCTga2KeqKsn8qlqV5DPAxVV1XssRJUmSJKmTBmrGcAPuBX4KnJnkGOCBmRyUZDzJZJLJu+9f2deAkiRJktRFg1gMH+Fnc80BqKpHgOcA5zP1vcJLZnKyqpqoqrGqGttpux03c1RJkiRJ6r5BXEr6fWDfJE9mqhS+EPhqkrnAtlX1+STXAN9pxt8HzGsnqiRJkiR136AVw6qqHyT5Z2A5cCtwffPcPOCiJHOAAG9p9v8j8JEkS4Djquq7sx1akiRJkrpsYIphkp2BuwGq6h3AO6YZ9py1d1TVVfhzFZIkSZK00QaiGCZ5KnA5cHo/X2er3bZlt1MO6udLSJIkSVLnDEQxrKofAc9sO4ckSZIkjaJBvCupJEmSJGkWDcSM4Wx5+I77uP0Dl7cdYyTstuTwtiNIkiRJmiFnDCVJkiRpxHWiGCZZkWRBs7267TySJEmSNExmvRhmSicKqSRJkiSNglkpaEkWJrklyd8C1wF/nOTaJMuTvLtn3IVJlia5Ocn4Bs758SQv73l8bpLf7N+7kCRJkqThNJszd78MfAz4A+BpTP1Y/SLgoCSHNWNeX1UHAWPAkuZH79flTOBEgCQ7AAcDn+9PdEmSJEkaXrNZDL9fVdcAL2r+Xc/U7OE+wN7NmCVJbgCuAXbv2f9zquorwF5JdgVeDZxfVY+sPS7JeJLJJJN3r75ns74hSZIkSRoGs/lzFfc3fwP8z6r6u94nkxwOHAEsrqoHklwOzNnAOT8OHA+8Cnj9dAOqagKYADjwGb9cG5ldkiRJkoZWGzeBuRR4fZK5AEme1sz67QCsbErhPsDzZnCus4FTAKrq5v7ElSRJkqThNus/cF9VlyX5FeDqJACrgdcClwBvTLIc+DZTy0k3dK7bk9wCXNi/xJIkSZI03GalGFbVCmD/nsfvB94/zdCj1nH8wp7tuY9vJ9mWqe8hfnIzRZUkSZKkkdPZ3xNMcgTwLeCvq8q7ykiSJEnSRpr1paSbS1X9b+AZT+SYrXadx25LDu9PIEmSJEnqqM7OGEqSJEmSNg+LoSRJkiSNuM4uJd0Yj9xxD3d88LNtxxgJu578srYjSJIkSZohZwwlSZIkacQNVDFMsrr5+9Qk5zXbJyT5m3aTSZIkSdLwGsilpFX1I+C4tnNIkiRJ0igYqBnDxyVZmOSmafa/JMnVSRYkeVGzfV2STyWZO925JEmSJEnrN5DFcDpJjgbeCby42fUu4Iiq+jVgEnhrW9kkSZIkqcsGcinpNF4AjAEvqqp7k7wU2Be4KgnA1sDV0x2YZBwYB3j6jrvMTlpJkiRJ6pCuFMPvAXsAz2RqdjDAF6vq1Rs6sKomgAmARc/Yu/oZUpIkSZK6qCtLSb8PHAN8LMl+wDXA85PsBZBk2yTPbDOgJEmSJHVVV4ohVfVt4HjgU8D2wAnAJ5MsZ6oo7tNeOkmSJEnqroFaSlpVc5u/K4D9m+2zgbOb7euZ+m4hwHeBZ892RkmSJEkaNgNVDPtty113YNeTX9Z2DEmSJEkaKJ1ZSipJkiRJ6o9Ujc6NOpPcB3y77RzaZAuAO9sOoU3iNRwOXsfh4HUcDl7H4eB1HA6Dfh1/sap+7nf8RmopKfDtqhprO4Q2TZJJr2O3eQ2Hg9dxOHgdh4PXcTh4HYdDV6+jS0klSZIkacRZDCVJkiRpxI1aMZxoO4A2C69j93kNh4PXcTh4HYeD13E4eB2HQyev40jdfEaSJEmS9PNGbcZQkiRJkrSWkSiGSY5M8u0k30nyzrbzaOMkWZHkxiTLkky2nUczk+SjSe5IclPPvp2SfDHJrc3fHdvMqA1bx3U8Ncm/N5/JZUle3GZGbViS3ZP8S5Jbktyc5M3Nfj+THbGea+jnsUOSzEnyjSQ3NNfx3c1+P4sdsp7r2MnP49AvJU2yBfCvwK8DPwSuBV5dVd9sNZiesCQrgLGqGuTfhdFakhwGrAY+VlX7N/v+f+Duqjqt+X/W7FhVf9BmTq3fOq7jqcDqqjq9zWyauSRPAZ5SVdclmQcsBV4BnICfyU5YzzX8bfw8dkaSANtV1eokWwFfBd4MHIOfxc5Yz3U8kg5+HkdhxvA5wHeq6ntV9RDwj8DLW84kjYyqugK4e63dLwfOabbPYep/1GiAreM6qmOq6sdVdV2zfR9wC/A0/Ex2xnquoTqkpqxuHm7V/Cv8LHbKeq5jJ41CMXwa8IOexz/E/wLtqgIuS7I0yXjbYbRJdquqH8PU/8gBdm05jzbem5Isb5aauuSpQ5IsBJ4FfB0/k5201jUEP4+dkmSLJMuAO4AvVpWfxQ5ax3WEDn4eR6EYZpp9nW3yI+75VfVrwFHAyc3SNknt+RCwJ7AI+DHwF62m0YwlmQucD5xSVfe2nUdP3DTX0M9jx1TVo1W1CHg68Jwk+7ccSRthHdexk5/HUSiGPwR273n8dOBHLWXRJqiqHzV/7wAuYGqZsLrp9uZ7Mo9/X+aOlvNoI1TV7c3/QXwM+Ah+Jjuh+R7M+cC5VfXpZrefyQ6Z7hr6eeyuqloFXM7U99L8LHZU73Xs6udxFIrhtcDeSX4pydbAq4DPtJxJT1CS7Zov2ZNkO+BFwE3rP0oD7DPA65rt1wEXtZhFG+nx//HSOBo/kwOvuVHC3wO3VNUZPU/5meyIdV1DP4/dkmSXJPOb7W2AI4Bv4WexU9Z1Hbv6eRz6u5ICNLeI/StgC+CjVfXedhPpiUqyB1OzhABbAv/gdeyGJJ8EDgcWALcDfwpcCPwz8Azg34DfqipvbDLA1nEdD2dqmUwBK4D/9vh3YzSYkhwCXAncCDzW7P4jpr6j5meyA9ZzDV+Nn8fOSHIAUzeX2YKpiZp/rqo/S7IzfhY7Yz3X8eN08PM4EsVQkiRJkrRuo7CUVJIkSZK0HhZDSZIkSRpxFkNJkiRJGnEWQ0mSJEkacRZDSZIkSRpxFkNJkhpJliS5Jcm5bWeRJGk2+XMVkiQ1knwLOKqqbuvZt2VVPdJiLEmS+s4ZQ0mSgCQfBvYAPpPkniQTSS4DPpZklyTnJ7m2+ff85pidk1yW5Pokf5fk+0kWJFmY5Kaec78tyanN9p5JLkmyNMmVSfZp9p+d5ANJvpbke0mO6zn+HUluTHJDktOac1zX8/zeSZbOzn9SkqRhtGXbASRJGgRV9cYkRwIvAN4EvAw4pKoeTPIPwF9W1VeTPAO4FPgV4E+Br1bVnyV5CTA+g5eaAN5YVbcmeS7wt8B/aZ57CnAIsA/wGeC8JEcBrwCeW1UPJNmpqu5uyuuiqloGnAicvTn+c5AkjSaLoSRJ0/tMVT3YbB8B7Jvk8ee2TzIPOAw4BqCqPpdk5fpOmGQucDDwqZ5zPblnyIVV9RjwzSS79bz2WVX1QPM6dzf7zwROTPJW4JXAczbubUqSZDGUJGld7u/ZfhKwuKcoAtCUu+m+rP8IP/t1jTk951lVVYvW8Zprek/f83e61zifqRnLLwNLq+qudZxTkqQN8juGkiRt2GVMLS8FIMmiZvMK4Phm31HAjs3+24Fdm+8gPhl4KUBV3QvcluS3mmOS5MAZvPbrk2zbHLNTc66fMrWk9UPAWZv6BiVJo81iKEnShi0BxpIsT/JN4I3N/ncDhzU3gnkR8G8AVfUw8GfA14GLgW/1nOt44A1JbgBuBl6+vheuqkuY+r7hZJJlwNt6nj6XqdnEyzbp3UmSRp4/VyFJ0maSZAUwVlV3ztLrvQ3Yoar+eDZeT5I0vPyOoSRJHZTkAmBP/vOOppIkbTRnDCVJkiRpxPkdQ0mSJEkacRZDSZIkSRpxFkNJkiRJGnEWQ0mSJEkacRZDSZIkSRpxFkNJkiRJGnH/B0lS/0lJhgutAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting word frequency of False Negative instances\n",
    "\n",
    "FNlist = X_test[(y_test == 1) & (lr_predictions == 0)].tolist()\n",
    "FNstring = ''.join(FNlist)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "FNtokens = word_tokenize(FNstring)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "FN_counted = Counter(FNtokens)\n",
    "\n",
    "FN_word_freq = pd.DataFrame(FN_counted.items(),\n",
    "                            columns=['word','frequency']).sort_values(\n",
    "    by='frequency',ascending=False)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='frequency',y='word',data=FN_word_freq.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='frequency', ylabel='word'>"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting word frequency of False Positive instances\n",
    "\n",
    "FPlist = X_test[(y_test == 0) & (lr_predictions == 1)].tolist()\n",
    "FPstring = ''.join(FPlist)\n",
    "\n",
    "FPtokens = word_tokenize(FPstring)\n",
    "\n",
    "FP_counted = Counter(FPtokens)\n",
    "\n",
    "FP_word_freq = pd.DataFrame(FP_counted.items(),\n",
    "                            columns=['word','frequency']).sort_values(\n",
    "    by='frequency',ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='frequency',y='word',data=FP_word_freq.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are not a lot of insights from the graphs as the most recurring words are naturally the stopwords which we did not remove from the sentences due to the reason highlighted above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on observing the FN and FP sentences, the model failed to predict some instances correctly due to a couple of reasons. These reasons have been listed below with examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Sarcasm and the use of Irony (leading to False Positives)**\n",
    "\n",
    "As with most NLP models, it is considerably challenging to identify the level of negation in sarcastic or ironic statements as they do not contain negative words and their meanings are often hidden in context or in the tone of the sentence. This can potentially lead to False Positives, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       0\n",
      "45  i dressed up to be treated so rudely\n",
      "54  say bye bye to your tip lady        \n"
     ]
    }
   ],
   "source": [
    "# example of sarcastic sentences which came up as False Positives\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.max_colwidth', -1,\n",
    "                       ):\n",
    "    print(FP.loc[[45,54]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) The use of positive words in negative sentences (leading to False Positives)**\n",
    "\n",
    "There are some sentences that are negative but contain positive words such as good or better leading to some degree of ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                            0\n",
      "2   seems like a good quick place to grab a bite of some familiar pub food but do yourself a favor and look elsewhere        \n",
      "19  we ve have gotten a much better service from the pizza place next door than the services we received from this restaurant\n"
     ]
    }
   ],
   "source": [
    "# example of negative sentences with positive words which came up as False Positives\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.max_colwidth', -1,\n",
    "                       ):\n",
    "    print(FP.loc[[2,19]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) The use of negative words in positive statements (leading to False Negatives)**\n",
    "\n",
    "There are a lot of positive sentences that used the words 'not' or 'dont' and got categorized as negative statements leading to False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                       0\n",
      "13  because both ears are occupied background is not distracting at all                                                                                 \n",
      "56  i don t know exactly what it is about this movie but we latched on to this endearing movie and it has become a special part of our family s memories\n"
     ]
    }
   ],
   "source": [
    "# example of negative sentences with positive words which came up as False Positives\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.max_colwidth', -1,\n",
    "                       ):\n",
    "    print(FN.loc[[13,56]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
